[
["index.html", "Data Analysis in Social Science 3 1 Introduction 1.1 Things to do before the next class", " Data Analysis in Social Science 3 Alexey Bessudnov, expanded and edited by Max Shilling (BSc Sociology student 2018) 2018-07-23 1 Introduction This is a website for the Data Analysis in Social Science 3 module at the University of Exeter (SOC2094/3094 POL2094/3094) as offered in Term 2 in 2018. The website will be updated with new R Markdown scripts as the course progresses. All the scripts are provided on the ‘as is’ basis. The idea for this module is to teach you how to work with complex longitudinal data sets using data from the Understanding Society, a longitudinal household survey conducted in the UK. You will learn how to read complex data into R, manipulate and summarise data using dplyr, merge and restructure data frames, visualise data using ggplot2, create statistical reports with R Markdown and (possibly) interactive applications with Shiny. For more details see the module outline. The module is organised according to the “flipped classroom” pedagogy. This means that you read new material and do exercises before the class, and in class we work together on the exercises and discuss how what you learned at home can be applied to the Understanding Society data. The readings and exercises mostly come from the R for Data Science book by G.Grolemund and H.Wickham. The pre-requisites for this module are SOC/POL1041 and SOC/POL2077. All the scripts and other materials are available in the Github repository for the module: https://github.com/abessudnov/dataanalysis3 1.1 Things to do before the next class Before coming to class 2 please do the following: Register an account with the UK Data Service, create a data usage (or join the existing data usage that I have created) and download the Understanding Society data in the tab delimited format (SN6614). Read the User Manual and familiarise yourself with the structure of the data. Install Git and register an account on Github (if you do not have it already). Then you can either create a new repository for this module or fork my repository (see the link above). Create a project in R Studio for this repository. To learn how Git and Github work take this free online course: https://www.datacamp.com/courses/introduction-to-git-for-data-science/ In the root folder for your project create a folder “data” and put there the Understanding Society data as you downloaded them. The next subfolder must be “UKDA-6614-tab”. Never change anything in this folder. Also create an empty “myData” folder in the root folder. You do not want to track these two folders on Github. To avoid this, include the following two lines in your .gitignore file: data/ myData/ Read ch.11 (Data Import) from R for Data Science and do the exercises - http://r4ds.had.co.nz/data-import.html "],
["module-outline.html", "2 Module outline 2.1 Practical arrangements 2.2 Aims of the module 2.3 Attendance 2.4 Assessment 2.5 Syllabus plan 2.6 Reading list", " 2 Module outline 2.1 Practical arrangements Classes: Monday, 11.30am - 1.30pm, WSL 220 Classes begin on 15 January and end on 26 March. The class on 22 January (week 2) has been cancelled and moved to Friday 2 February, 10.30 - 12.30, WSL 220. Office hours (Amory A341) Monday, 2-3pm Friday, 12-1pm Email: A.Bessudnov [at] exeter.ac.uk 2.2 Aims of the module This is a fourth module in the data analysis in the social sciences series. In the Introduction to Social Data you learned the basics of descriptive statistics and R. Data Analysis 1 introduced you to statistical inference. Data Analysis 2 covered linear regression analysis. In Data Analysis 3 we are not going to learn new statistical techniques, but will focus on how to apply the techniques you already know to the analysis of real-life data sets and how to produce statistical reports. This is a skill that you may need in a variety of jobs where data analytic expertise is required, such as marketing analysis, policy analysis in various fields, web analytics, data journalism, academic research, etc. You already know how to use R to describe data and run simple statistical models. However, real-life data rarely come in the form of a perfectly formatted csv file ready for the analysis. The real life data sets often need to be reshaped, merged, recoded, aggregated and modified in various ways before you can even start your analysis. Unless you know how to do this you will not be able to produce good statistical reports. This year in this module we will use data from the Understanding Society, a large household panel study conducted in the UK. In the Immigration module we already used the cross-sectional Understanding Society data. In this module we will work with the longitudinal data, which introduces a number of technical challenges. Throughout the module we will use R for statistical analysis. You are expected to know the basics of data analysis in R. The only way to learn data analysis is to do data analysis. I will not be able to teach you this, but I can guide your independent learning. This year we will try the “flipped classroom” model of teaching. This means that you will be expected to read and master the required material BEFORE the class and we will use the time in class to answer additional questions and check your solutions rather than introduce new material. The pre-requisites for this module are POL/SOC1041 and POL/SOC2077. 2.3 Attendance This module is quite technical. As with other technical skills, missing some initial bits means that you may not be able to catch up. Attendance in this module is crucial. If you do not attend you will not be able to do well in this module. Even skipping a couple of classes will have negative consequences for your understanding of the material. Another negative consequence will be that you will slow the rest of the class down as I will have to explain the same things several times. If you plan not to attend classes please do not take this optional module. 2.4 Assessment The assessment for this module is a report of 3,500 words (in addition to figures and tables) with the results of statistical analysis you will undertake. This will be 100% of your final mark for this module. You will be given questions for the reports later in the module. In your analysis you will use the Understanding Society data. The deadline for submitting your reports through eBart is 29 March at 2pm. You will receive your marks and feedback by 5 May. Late submissions up to two weeks after the deadline will be capped at 40%. Submissions that are late for more than two weeks will not be accepted. 2.5 Syllabus plan I may change some topics as we proceed. Data structures in R Manipulating data with dplyr Longitudinal data in R. Wide and long formats. Reshaping Data visualisation with ggplot2 Producing statistical reports with R Markdown Interactive applications with Shiny Loops and other control structures. The apply family of functions Writing functions in R 2.6 Reading list The main text for this module: G.Grolemund &amp; H.Wickham. (2016). R for Data Science. Freely available at http://r4ds.had.co.nz/ In addition to this you can the following sources (among many others books on R). H.Wickham. (2015). ggplot2. Elegant Graphics for Data Analysis. 2nd ed. Springer. W.Chang. (2013). R Graphics Cookbook. O’Reilly. P.Spector. (2008). Data Manipulation with R. Springer. N.Matloff. (2011). The Art of R Programming. No Starch Press. H.Wickham. (2014). Advanced R. Chapman &amp; Hall. "],
["assignment.html", "3 Assignment", " 3 Assignment Your assignment for this module is to choose a topic, conduct an independent statistical analysis with the Understanding Society data and write up your results in a report that is about 3,500 words long. I wanted to give you as much flexibility as possible in preparing the report. I will not provide a detailed guidance on what you should analyse and how you should this. As this is an advanced module I expect you to be able to formulate a research question, identify the data you need and conduct the analysis independently. In other words, the idea is to throw you into the sea of data and find out if you can come up with a nice statistical report that answers a well defined question. However, there are a few rules. You must use the Understanding Society data and I suggest you use data from the indresp files (these are individual adult questionnaires). You must use longitudinal data, i.e. data from more than one wave and preferrably all seven waves of the Understanding Society. This will depend on your question though. If you only have data at two time points available and produce good analysis this is totally fine. But if you have data in all seven waves and only use two this is not fine. Generally you would select one time-varying variable and explore changes over time, in the whole sample and different population subgroups. For example, you may explore how people’s incomes changed from 2008 to 2016. You may want to conduct your analysis by gender, age group, location, etc. Other possible variables: Health Employment and job mobility State benefits Any other topic that you find interesting and that has longitudinal data available in the Understanding Society. You cannot use data on political interest and political preferences as we will explore these data in class. You must prepare your report in R Markdown. Submit the pdf file (with all the R syntax visible) through eBart. You do no need to submit your work on Github. Please keep your R syntax clear and provide commentary explaining to me what you do. The deadline for your reports is 3 May at 2pm. I suggest the following steps for your reports. First you need to find a topic that interests you and that has longitudinal data available. Check the User Manual, the questionnaires and data dictionaries for individual waves. Note that the Understanding Society has some modules that are present in each wave and some rotating modules that are only present in one or several waves. Once you have found a variable that interests you make sure that it is present in the data at least at two or more time points. Next you need to read the data into R. Start simple and only read in the data for your outcome variable and maybe sex and age. You will be able to add more variables later as long as you keep your syntax. Clean the data and look at the distributions. Think about the best way to describe and visualise your data. Do you see any interesting patterns and trends? At this stage you should start thinking about the story you want to tell us with your analysis. I do not expect you to do anything fancy statistically. Just providing descriptive statistics and visualisations is fine, as long as I can see that you have thought carefully about which statistics and graphs are best to answer your questions. Every table and chart you have in your report must contribute something to your story. That said, if you want to use some statistical modelling in your report (for example, linear regression) and you do this correctly this will be appreciated and I will give you extra marks for doing this. Once you have a feeling about the general direction of your analysis start adding the details. Maybe you want to explore some more variables; then you need to add them to the data set. For example, for the analysis of political interest I would start with looking at descriptive statistics for political interest for each wave and establish if it was stable or increased/decreased. Then I would think about how I can visualise the results. Then I may start adding details. Was the trend the same for men and women? Different age groups? Different parts of the country? Then if I want to do something fancy I would remember that in 2010 the UK had a general election. Can we get the date of the interview from the data and explore how political interest changed monthly in 2010? And then if I really want to do something very fancy I would read about applyng models with fixed effects to longitudinal data, talk to Alexey in his office hours and explore if change in people’s income over time is associated with the change in political interest. (The latter part is optional.) Write up the results. Start with a brief introduction. For political interest that would be approximately the following: Why are we interested in political interest? What happened in British politics between 2008 and 2016 that could affect the level of political interest? Maybe you can find and cite two or three papers that have already explored this topic. Then present your research questions. What are you aiming to achieve with your report? What questions will you answer? Briefly describe the data (variables you are going to use, what waves they are coming from, etc.). Present your statistical results. The structure of this part will depend on your results. This should not be just a collection of tables and graphs. Explain what you see in all those tables and graphs and why you have included them. Discussion. This is a very important part. You need to discuss here how the statistical results you have got contribute to our understanding of your topic (for example, political interest in Britain). Explain in substantive terms your results and discuss them. Why has political interest increased (or decresed, or ramained stable)? What factors contributed to this? The length of the report is 3,500 words, but I am not going to count your words and writing slightly more or slightly less is fine. Do not submit 100 pages. In the same way, if your report is obviously too short this is going to affect your mark. "],
["readdata.html", "4 Read data 4.1 Introduction to Reading Data 4.2 Reading common data files into R 4.3 Reading other data files 4.4 Saving datasets 4.5 Saving the working environment 4.6 Reading in multiple waves from Understanding Society", " 4 Read data Prerequisite: Chapter 11 ‘Data Import’ from R for Data Science, available at http://r4ds.had.co.nz/data-import.html 4.1 Introduction to Reading Data Once you have downloaded the data from the Understanding Society survey, the first thing you need to do is read the data into R. There are a number of ways to do this, and this class will cover loading data into R by using base R and both the readr and data.table packages. The data we will be loading into R is the individual adult questionnaire answers from wave 1 (UKDA-6614-tab/tab/us_w1/a_indresp.tab). This should be saved in the data folder you created in your project folder (this was covered in the Introduction section to the course). 4.2 Reading common data files into R 4.2.1 Ways to read data into R 4.2.1.1 Using base R To read this data into R using functions from base R, we can first use the read.table() function. To read the data in correctly, we need to use header = TRUE as the first row of the data contains the names of the variables, and also stringsAsFactors = FALSE, which stops R from treating text variables as factors. We can convert these into factors later, when necessary. UndSoc.1 &lt;- read.table(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;, header = TRUE, stringsAsFactors = FALSE) Different types of files need to read into R in different ways. The read.table() function reads data that is tab separated (the file will be called ‘name.tab’), the read.csv() function reads data that is comma separated (the file will be called ‘name.csv’) and read.delim() reads data that is separated in any way. These work in the same way, so once you’ve mastered one, you’ve mastered them all. 4.2.1.2 Using the readr package We can also read data into R using the package readr, part of the tidyverse package, with the read_tsv() command. This is the equivalent command to read.table() from base R. # We can either load the entire &#39;tidyverse&#39; package into R, which includes the readr package as well as others such as ggplot2, or just the &#39;readr&#39; package on its own. library(readr) UndSoc.2 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) The readr package also allows us to read different types of files into R. The commands read_csv() and read_delim() read comma and any type of separated data into R respectively. 4.2.1.3 Using the data.table package The final way we are going to read this data into R is by using the fread() function from the data.table package. The advantage of the fread() command is that it can read any type of separated data into R, without you having to change anything if the file type you are trying to read changes. library(data.table) UndSoc.3 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) ## Read 78.4% of 50994 rows Read 50994 rows and 1364 (of 1364) columns from 0.187 GB file in 00:00:03 4.2.2 Comparing these three methods One of the important differences between these three methods for reading data into R is the length of time they take to read the data. We can compare this by reading the data into R again, this time wrapping our code with the command system.time(). 4.2.2.1 Using base R # Base R system.time(UndSoc.1 &lt;- read.table(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;, header = TRUE, stringsAsFactors = FALSE)) ## user system elapsed ## 39.617 1.226 40.996 4.2.2.2 Using the readr package system.time(UndSoc.2 &lt;- read_tsv(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;)) ## user system elapsed ## 9.531 0.490 10.046 4.2.2.3 Using the data.table package system.time(UndSoc.3 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;)) ## Read 78.4% of 50994 rows Read 50994 rows and 1364 (of 1364) columns from 0.187 GB file in 00:00:03 ## user system elapsed ## 2.531 0.208 2.748 From this we can see clear differences in loading time. With small data sets, the difference between these three methods will not be very noticeable or important, but with larger data the increase in loading times the readr and data.table packages provide can be quite substantial. 4.2.3 Editing a dataset while reading it into R 4.2.3.1 Skipping rows of data Sometimes we do not want to read in the entire dataset we have into R, but instead want to ignore the first few rows. For example, if we were to do some sentiment analysis on Hamlet (found here: http://www.gutenberg.org/files/1524/1524-0.txt, we would want to only read in the play itself, not the introductions before the start of the play. We can use the skip = “” command to only read the file from the start of the play, with each line of the script counting as a row. Hamlet &lt;- read.delim(&quot;http://www.gutenberg.org/files/1524/1524-0.txt&quot;, skip = 30, header = FALSE) 4.2.3.2 Reading only select variables When working with large datasets, like the one you will be using for your assignment, there are only certain variables that are of interest. As a result, it makes sense to load in only these variables, to make analysing your data easier to do. Let’s say that we’re interested in how political interest is distributed across the UK, and want to analyse how this is differentiated by sex and age. The variables we need to read into R are these two (a_sex and a_dvage), as well as interest in politics (a_vote6) and the personal identification variable for each individual (a_pidp). We can use the select = “” command to do this. UndSoc.4 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;, select = c(&quot;pidp&quot;, &quot;a_sex&quot;, &quot;a_dvage&quot;, &quot;a_vote6&quot;)) 4.2.3.3 Setting NA values Sometimes, if we look at the raw data we are about to analyse, we see that there are a number of missing values. Instead of recoding these values as NA after we have loaded our data (found, in this example, at https://raw.githubusercontent.com/abessudnov/dataanalysis3/master/exData/Table3.txt), we can do this while reading our data into R using the na.strings = “” command. MissingData &lt;- read.table(&quot;exData/Table3.txt&quot;, header = TRUE, skip = 2, na.strings = c(&quot;*&quot;, &quot;**&quot;, &quot;--&quot;)) 4.3 Reading other data files 4.3.1 Excel In R, you can also read data that was created in Excel. Excel files are saved primarily as .xls or .xlsx files. Fortunately, after installing the readxl package, the command read_excel() can read both formats into R. Using the example Excel document found at (https://github.com/abessudnov/dataanalysis3/blob/master/exData/tableExcel.xlsx), we can easily read this into R. library(readxl) Excel &lt;- read_excel(&quot;exData/tableExcel.xlsx&quot;) When reading Excel files into R, read_excel() defaults to loading the first sheet. If there are multiple sheets in our document (by opening the Excel file we can see that there are 2 in this case), we can load different sheets in with the sheet = “” command. Excel2 &lt;- read_excel(&quot;exData/tableExcel.xlsx&quot;, sheet = 2) However, if we look at the sheet we have just loaded, we can see that there are two NA values, one of which is coded as “NA”. Furthermore, if we compare how these NA values appear in our data with the ones from our MissingData dataset, we can see that they aren’t actually coded as missing values, but instead as values called NA and “NA”. head(MissingData) ## Name Age Height Weight Sex ## 1 Alex 25 177 57 F ## 2 Lilly 31 NA 69 F ## 3 Mark NA 190 83 M ## 4 Oliver 52 179 75 M ## 5 Martha 76 &lt;NA&gt; 70 F ## 6 Lucas 49 183 NA M head(Excel2) ## # A tibble: 3 x 3 ## actor movie sentence ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A 1 NA ## 2 B 2 &quot;\\&quot;NA\\&quot;&quot; ## 3 C 3 15 To fix this, we need to set both these values as NA, which we can do with the na = “” command. Excel3 &lt;- read_excel(&quot;exData/tableExcel.xlsx&quot;, sheet = 2, na = c(&#39;NA&#39;, &#39;&quot;NA&quot;&#39;)) # Note that as one of the missing values is called &quot;NA&quot;, you have to use inverted commas (&#39;&#39;) around the entire value for R to change it to an NA value, rather than the usual speech marks (&quot;&quot;). Inverted commas and speech marks are interchangable in R, though if you use one to open a command, you cannot use the other to close it. We can now see that this dataset has true NA values in it for the missing data. head(Excel3) ## # A tibble: 3 x 3 ## actor movie sentence ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 1 NA ## 2 B 2 NA ## 3 C 3 15 4.3.2 SPSS As many people use SPSS instead of R to analyse data, there are times when you will have to use data that is intended for use in SPSS. The haven package allows us to do this, and as an example we will read a dataset containing some data from a survey. library(haven) SPSS &lt;- read_spss(&quot;exData/survey.sav&quot;) You can also use haven to read data in the Stata and SAS formats. 4.4 Saving datasets Once you have read your data into R you can save it as a file so you can load it back into R at a later date to continue working on it. Again, there are a number of different ways to do this. 4.4.1 Saving data as a text file Having read the first wave of data into R with only the variables we are interested in (see Reading only select variables), we can save this data as a text file using base R, without having to install any new packages. All we need to do is create a folder called myData in the folder where you have saved your project, and then you can save your dataset to this folder. write.csv(UndSoc.4, &quot;myData/UndSoc.4.csv&quot;) As you had to get specific permission to access the Understanding Society dataset, it is important you do not save this data to Github. This applies to every method of saving data from R we will cover here. Add the following line to your gitignore file to keep the myData folder untracked: myData/ 4.4.2 Saving data as an Excel file To save our data as an Excel file, we need to first install the writexl package, and use the command write_xlsx(). library(writexl) write_xlsx(UndSoc.4, path = &#39;myData/UndSoc.4.xlsx&#39;, col_names = TRUE) 4.4.3 Saving data as an SPSS file We can use the haven package we used to read files saved for use in SPSS to write data as SPSS files too, using the write_sav() command. write_sav(UndSoc.4, &quot;myData/UndSoc.4.sav&quot;) 4.4.4 Saving an object as an RDS file Finally, we can just save a file for future use in R as an RDS file. It will work faster with large objects, but it will only allow saving one object (such as a data frame) at a time and it will also drop the name of the object while saving. saveRDS(UndSoc.4, &quot;myData/UndSoc.4.rds&quot;) 4.4.5 Loading these datasets back into R To read any of these datasets back into R, use what you learnt in Reading common data files into R. When loading an RDS file back into R, simply use the readRDS() command. Note that we assign a new name to the object. RDS &lt;- readRDS(&quot;myData/UndSoc.4.rds&quot;) 4.5 Saving the working environment If you want to save an entire workspace, rather than just individual files, the command save.image() does this. This saves not only all loaded data frames but any saved objects: models, plots, functions, etc. Before saving the entirer workspace we’ll remove all the objects from it, except two: Hamlet and MissingData. We’ll do this just to save time, otherwise saving the data image will take too long. # First we&#39;ll print all the objects we currently have in the memory. ls() ## [1] &quot;Excel&quot; &quot;Excel2&quot; &quot;Excel3&quot; &quot;Hamlet&quot; &quot;MissingData&quot; ## [6] &quot;RDS&quot; &quot;SPSS&quot; &quot;UndSoc.1&quot; &quot;UndSoc.2&quot; &quot;UndSoc.3&quot; ## [11] &quot;UndSoc.4&quot; # Then we can remove all the objects, except the 4th and the 5th. rm(list = ls()[-c(4,5)]) # Saving the workspace. save.image(&quot;myData/Workspace.RData&quot;) # Clearing the current workspace. rm(list = ls()) # Loading the workspace back into R. load(&quot;myData/Workspace.RData&quot;) 4.6 Reading in multiple waves from Understanding Society For your assignment, you are required to analyse at least two waves of data from the Understanding Society dataset. We will cover how to join multiple waves together in a future lesson, but before doing this, let’s read in the first two waves of Understanding Society. To do this, we need to use the function fread() from the data.table package, as the data are tab separated. # First, we clear the current workspace. rm(list = ls()) UndSoc1 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) ## Read 78.4% of 50994 rows Read 50994 rows and 1364 (of 1364) columns from 0.187 GB file in 00:00:03 UndSoc2 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot;) ## Read 54.9% of 54597 rows Read 91.6% of 54597 rows Read 54597 rows and 1615 (of 1615) columns from 0.233 GB file in 00:00:04 As we discussed earlier in this class, these files take a lot longer to load into R than other data files you have used in the past. This is because the files themselves are large, and take up a lot of space in the memory. We can see just how much space they take up by using the object.size() command. object.size(UndSoc1) ## 286020872 bytes object.size(UndSoc2) ## 364341464 bytes However, this does not give us an answer that we can easily interpret. Therefore, by using the format() command, we can specify how we want R to show us this data. In this case, by adding units = “” we can tell R to show us how large the files are in specific units. # By adding units = &quot;auto&quot; R automatically chooses the clearest way to show us the size of the files. format(object.size(UndSoc1), units = &quot;auto&quot;) ## [1] &quot;272.8 Mb&quot; format(object.size(UndSoc2), units = &quot;auto&quot;) ## [1] &quot;347.5 Mb&quot; To make the files we are working with smaller, and thus make R carry out our analysis quicker, we can select only the variables we need for our analysis. We are only going to load a few variables here to keep this simple; you can always add more to your analysis. Here, as we are looking at level of interest in politics, they are: pidp: this is the id number given to each respondent to identify them in each wave a_sex: sex from wave 1 a_dvage: age from wave 1 a_vote6: level of interest in politics from wave 1 b_sex: sex from wave 2 b_dvage: age from wave 2 b_vote6: level of interest in politics from wave 2 By using what we covered earlier, we can select only the variables we want to read into R, making the loading times decrease significantly as they are much smaller datasets. UndSoc1ed &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;, select = c(&quot;pidp&quot;, &quot;a_sex&quot;, &quot;a_dvage&quot;, &quot;a_vote6&quot;)) UndSoc2ed &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot;, select = c(&quot;pidp&quot;, &quot;b_sex&quot;, &quot;b_dvage&quot;, &quot;b_vote6&quot;)) We can check that these are much smaller objects, and that our code was successful. format(object.size(UndSoc1ed), units = &quot;auto&quot;) ## [1] &quot;798.3 Kb&quot; format(object.size(UndSoc2ed), units = &quot;auto&quot;) ## [1] &quot;854.6 Kb&quot; head(UndSoc1ed) ## pidp a_sex a_dvage a_vote6 ## 1: 68001367 1 39 3 ## 2: 68004087 1 59 2 ## 3: 68006127 2 39 4 ## 4: 68006135 2 17 4 ## 5: 68006807 2 72 4 ## 6: 68007487 2 57 1 head(UndSoc2ed) ## pidp b_sex b_dvage b_vote6 ## 1: 68004087 1 60 2 ## 2: 68006127 2 40 4 ## 3: 68006807 2 73 4 ## 4: 68007487 2 58 2 ## 5: 68008167 2 39 4 ## 6: 68008171 1 52 -7 As we no longer have any use for the original data we loaded into R, we can remove them from R to free up the memory they are unnecessarily taking up. rm(UndSoc1, UndSoc2) We can then save these datasets so we can easily load them into R at a later date to continue working on them. We will use these in future classes. Here, we save the workspace, which includes just waves 1 and 2 of the Understanding Society data, for future use. save.image(&quot;myData/ReadData.RData&quot;) "],
["transformdata.html", "5 Transform data 5.1 Introduction to transforming data 5.2 Operators recap 5.3 The pipe operator (%&gt;%) 5.4 Select variables 5.5 Select cases 5.6 Recode variables Both base R and dplyr using ifelse 5.7 Create new variables 5.8 Sort data", " 5 Transform data Prerequisite: Chapter 11 ‘Data transformation’ from R for Data Science, available at http://r4ds.had.co.nz/transform.html 5.1 Introduction to transforming data Once you have imported your data in R you will usually want to clean it, transform it and produce some data summaries. All these tasks can be accomplished with base R. However, it is usually more convenient to use specialised packages for this, such as dplyr and data.table. In this module we will use dplyr. We are going to work with wave 1 from the Understanding Society dataset. # First, install the &#39;data.table&#39; package. library(data.table) # Revisit the class &quot;Read Data&quot; if you need a reminder on how to best read data into R. W1 &lt;- fread(&quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot;) ## Read 78.4% of 50994 rows Read 50994 rows and 1364 (of 1364) columns from 0.187 GB file in 00:00:03 5.2 Operators recap However, before we learn how to transform data in R, we are going to recap on operators you will need that you should have covered in other courses using R. These operators are relational and logical. 5.2.1 Relational operators Relational operators are used when comparing values, and will help with selecting cases, recoding and creating variables in your assignment. Below is a table with some useful relational operators available in R. Operator Description &lt; Less than &gt; Greater than &lt;! Not less than &gt;! Not greater than &lt;= Less than or equal to &gt;= Greater than or equal to == Equal to != Not equal to For example, if we code x to be 5 and y to be 6, we can use these operators to compare the two. R gives us a TRUE or FALSE reading for each comparison we make. x &lt;- 5 y &lt;- 6 x &lt; y ## [1] TRUE x == y ## [1] FALSE x != y ## [1] TRUE If we were selecting variables from a data frame that were greater than x, for example, we could use these operators to do so. This will be covered later in this class. 5.2.2 Logical operators Logical operators are used to help compare values, and are especially useful when comparing multiple values. Below is a table of some useful logical operators available in R. Operator Description &amp; And | Or z &lt;- 7 x &amp; y &lt; y ## [1] FALSE x | z &lt; y ## [1] TRUE x | z &lt;! y ## [1] TRUE Again, these operators will be used more later in this class, and are necessary when recoding values. # Cleaning up the working environment. rm(x, y, z) 5.3 The pipe operator (%&gt;%) The first step in transforming data is understanding what the pipe operator %&gt;% is, and how it works. To do this, we are going to create a simple table showing the proportions of responses given to the variable political interest (a_vote6). To begin with, we create a table showing the numbers of responses given for each category. table(W1$a_vote6) ## ## -9 -7 -2 -1 1 2 3 4 ## 118 3262 42 42 4882 15862 14017 12769 To convert this table into a table of proportions we do the following: prop.table(table(W1$a_vote6)) ## ## -9 -7 -2 -1 1 ## 0.0023139977 0.0639683100 0.0008236263 0.0008236263 0.0957367533 ## 2 3 4 ## 0.3110562027 0.2748754755 0.2504020081 To print this table in an easy-to-read manner, we would usually use the kable() function from the knitr package, and would need to convert the table into a data frame first and then apply the function kable(). # Loading the &#39;knitr&#39; package into R. library(knitr) # Printing the table of proportions. kable(data.frame(prop.table(table(W1$a_vote6))), digits = 2) Var1 Freq -9 0.00 -7 0.06 -2 0.00 -1 0.00 1 0.10 2 0.31 3 0.27 4 0.25 As you can see, at this point we have four ‘nested’ functions (functions within other functions) and the code becomes difficult to read. With the pipe operator %&gt;% (Shift+Ctrl+M on Windows or Shift+Cmd+M on Mac) you can achieve the same result with the following code: # Loading the &#39;tidyverse&#39; package, in which the package containing the pipe operator (&#39;dplyr&#39;) is found. library(tidyverse) W1$a_vote6 %&gt;% table() %&gt;% prop.table() %&gt;% data.frame() %&gt;% kable(digits = 2) . Freq -9 0.00 -7 0.06 -2 0.00 -1 0.00 1 0.10 2 0.31 3 0.27 4 0.25 The pipe operator passes the results of the execution of a function to the next function, essentially treating the entire chunk of code as a ladder, which is executed from top to bottom, with each extra line of code being run on the results from the previous line. This makes code easier to write, read and understand. 5.4 Select variables For your assignment, you will only want to work with select variables from Understanding Society. You learnt how to read in only select variables from a dataset in the Read data class, though if you have already loaded in a dataset (as we have here) and want to select only certain variables from this, you need to learn how to transform the data as you do not want to have to keep loading data in to R every time you decide to add or remove a variable from your analysis. Here, we will select the variables for sex, age, place of birth and measures of weight and height, as well as the personal identification variable for each individual. In base R you could use the following code: newW1 &lt;- subset(W1, select = c(&quot;pidp&quot;, &quot;a_sex&quot;, &quot;a_dvage&quot;, &quot;a_ukborn&quot;, &quot;a_hlht&quot;, &quot;a_hlhtf&quot;, &quot;a_hlhti&quot;, &quot;a_hlhtc&quot;, &quot;a_hlwt&quot;, &quot;a_hlwts&quot;, &quot;a_hlwtp&quot;, &quot;a_hlwtk&quot;)) head(newW1, 3) ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## 1: 68001367 1 39 1 1 6 0 -8 1 ## 2: 68004087 1 59 5 1 5 11 -8 2 ## 3: 68006127 2 39 1 1 5 1 -8 1 ## a_hlwts a_hlwtp a_hlwtk ## 1: 15 8 -8 ## 2: -8 -8 70 ## 3: 14 7 -8 However, with dplyr, we are able to do this with much less code, as follows. newW1 &lt;- W1 %&gt;% select(pidp:a_dvage, a_ukborn, a_hlht:a_hlwtk) head(newW1, 3) ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## 1: 68001367 1 39 1 1 6 0 -8 1 ## 2: 68004087 1 59 5 1 5 11 -8 2 ## 3: 68006127 2 39 1 1 5 1 -8 1 ## a_hlwts a_hlwtp a_hlwtk ## 1: 15 8 -8 ## 2: -8 -8 70 ## 3: 14 7 -8 As some of the variables we want to select from the W1 data appear next to one another, we can use a colon to select these adjacent variables, meaning we do not need to write out every variable we want to select. # Clearing W1 from the working environment. rm(W1) 5.5 Select cases Relatedly, sometimes you will want to only work with certain cases in variables that meet certain conditions. Here, we only include women aged 18 to 25 in a new data frame. To do this in base R, we use what we recapped in Operators recap and can save the new data frame as follows. women &lt;- newW1[newW1$a_sex == 2 &amp; (newW1$a_dvage &gt;= 18 &amp; newW1$a_dvage &lt;=25),] Once again, by using dplyr, our code will be shorter and easier to read. newW1 %&gt;% filter(a_sex == 2 &amp; (a_dvage &gt;= 18 &amp; a_dvage &lt;=25)) %&gt;% head(3) ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## 1 68010207 2 24 1 1 5 5 -8 1 ## 2 68010891 2 23 1 -7 -7 -7 -7 -7 ## 3 68023131 2 23 1 1 5 9 -8 1 ## a_hlwts a_hlwtp a_hlwtk ## 1 10 10 -8 ## 2 -7 -7 -7 ## 3 11 13 -8 # Note: In this case we are not saving the new data frame as an object, but instead printing the first three rows from the data to demonstrate the result. We can make this as complicated as we want and use more than one variable. For example, here is a new data frame that includes only people born in Wales or Northern Ireland and over the age of 40. newW1 %&gt;% filter((a_ukborn == 3 | a_ukborn == 4) &amp; a_dvage &gt; 40) %&gt;% head(3) ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## 1 68051011 2 41 3 1 5 5 -8 1 ## 2 68062567 2 50 4 1 5 1 -8 1 ## 3 68189727 2 95 3 1 5 4 -8 1 ## a_hlwts a_hlwtp a_hlwtk ## 1 10 2 -8 ## 2 9 2 -8 ## 3 10 3 -8 5.6 Recode variables Both base R and dplyr using ifelse Wanting to change the output of variables is common when working with data, as variables are often coded in ways that make them easy to code for those recording the variables, but difficult to understand without a code book for people analysing the data. This is the case with some of the variables in Understanding Society. The ifelse command is used to recode variables, and works by a) using a relational operator to specify the range of values you want to include from the original variable, b) setting what you want to recode this value/set of values as, c) finally setting what values outside the range you specified are recoded as. As a simple example, here we create a new dummy variable using base R named a_Scotland that takes the value of 1 if a person was born in Scotland (with a value of 2 from the a_ukborn variable) and 0 otherwise. newW1$a_Scotland &lt;- ifelse(newW1$a_ukborn == 2, 1, 0) However, there are often times when you will want to recode a number of values from a variable. If you look at the code book for Understanding Society, you can see that the variable ukborn is coded to give numerical values that correspond to a country of birth. To make interpreting this variable easier, both for us and for anyone reading our analysis of the Understanding Society data, we can recode this variable to instead show the country name, rather than a numerical value, as its output. In this case, as there are multiple values we want to recode, the final clause in the ifelse() command can be set as another ifelse() command to recode other values from this variable, before setting those outside all of the values we are interested in (such as responses where this question was refused an answer) as NA to finish the command. # Instead of recoding the variable and overwriting the original, we create a new variable to put the recoded variable in, as if we make a mistake with our code and have overwritten the original data, we will have to reload the dataset and start this process again. It is good coding practice to never overwrite original data. newW1$a_uk &lt;- ifelse(newW1$a_ukborn == 1, &#39;England&#39;, ifelse(newW1$a_ukborn == 2, &#39;Scotland&#39;, ifelse(newW1$a_ukborn == 3, &#39;Wales&#39;, ifelse(newW1$a_ukborn == 4, &#39;NIR&#39;, ifelse(newW1$a_ukborn == 5, &#39;Overseas&#39;, NA))))) Once again, however, dplyr makes this process shorter to write and easier to read. The recode command allows us to do this. However, this will overwrite our original variable, and as already discussed, this is bad practice. Consequently, we will use the mutate command (which we will explore in more detail in Create new variables) to make a new variable in which to put this recoding. # The command &#39;.default = NA_character_&#39; codes all the values that were not specifically matched (all negative values in our case) to missing values. AltW1 &lt;- newW1 %&gt;% mutate(a_placeBirth = recode(a_ukborn, &quot;1&quot; = &quot;England&quot;, &quot;2&quot; = &quot;Scotland&quot;, &quot;3&quot; = &quot;Wales&quot;, &quot;4&quot; = &quot;Northern Ireland&quot;, &quot;5&quot; = &quot;not UK&quot;, .default = NA_character_)) It is always a good idea to compare the distributions of the original and recoded variables to make sure that our code was correct. It is simplest to use the count() command to do this. AltW1 %&gt;% count(a_ukborn, a_placeBirth) ## # A tibble: 8 x 3 ## a_ukborn a_placeBirth n ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 -9 &lt;NA&gt; 6 ## 2 -2 &lt;NA&gt; 2 ## 3 -1 &lt;NA&gt; 8 ## 4 1 England 33480 ## 5 2 Scotland 3567 ## 6 3 Wales 2154 ## 7 4 Northern Ireland 2033 ## 8 5 not UK 9744 5.7 Create new variables As already mentioned, the mutate() command is used to create new variables, which can go far beyond merely recoding existing variables. Our next example is a much more complicated case, creating a new variable in which we code a variable for the Body Mass Index (BMI), which is defined as weight in kilograms divided by the square of height in meters: \\[BMI = \\frac{weight_{kg}}{{height_{m}}^2}\\] The problem we immediately encounter is that in our dataset some people gave their weight in kilograms (a_hlwtk) and some in stones and pounds (a_hlwts and a_hlwtp). Similarly, some people gave their height in centimetres (a_hlhtc) and others in feet and inches (a_hlhtf and a_hlhti). We need to start with converting the measures for everyone to kilograms and centimetres and then we will be able to create a variable for BMI. Imperial measurement Metric conversion 1 foot 40.38 centimetres 1 inch 2.54 centimetres 1 stone 6.35 kilograms 1 pound 0.45 kilograms W1mod &lt;- newW1 %&gt;% # Start your code by creating a new variable for height in centimetres. mutate(heightcm = ifelse(a_hlht == 1 &amp; a_hlhtf &gt; 0, a_hlhtf * 30.48 + a_hlhti * 2.54, ifelse(a_hlht == 2 &amp; a_hlhtc &gt; 0, a_hlhtc, NA))) %&gt;% # New variable &#39;heightcm&#39;: if height is measured in feet and inches (a_hlht == 1) and is not missing (a_hlhtf &gt; 0), # Multiply feet by 30.48 and inches by 2.54 to convert these measurements to centimetres and add them together, entering height as this new value. # If height is not measured in feet and inches, but centimetres instead (a_hlht == 2), and is not missing (a_hlhtf &gt; 0), enter height as this value, and if height is measured in neither feet and inches nor in centimetres, set the value for height as &#39;NA&#39;. # Now do the same for weight, converting into kilograms. mutate(weightkg = ifelse(a_hlwt == 1 &amp; a_hlwts &gt; 0, a_hlwts * 6.35 + a_hlwtp * 0.45, ifelse(a_hlwt == 2 &amp; a_hlwtk &gt; 0, a_hlwtk, NA))) %&gt;% # New variable &#39;weightkg&#39;: if weight is measured in stone and pounds (a_hlwt == 1) and is not missing (a_hlwts &gt; 0), # Multiply stone by 6.35 and pounds by 0.45 to convert these measurements to kilograms and add these together, entering weight as this new value. # If weight is not measured in stone and pounds, but kilograms instead (a_hlwt == 2), and is not missing (a_hlhtf &gt; 0), enter weight as this value, and if weight is measured in neither stone and pounds nor in kilograms, set the value for weight as &#39;NA&#39;. # Finally create a variable for BMI. mutate(bmi = weightkg / (heightcm / 100) ^ 2) # New variable &#39;bmi&#39;: &#39;weightkg&#39; / (&#39;hightcm&#39; / 100) ^ 2) Now we are able to look at the distribution of BMI across the Understanding Society dataset, using a histogram. hist(W1mod$bmi) 5.8 Sort data We can sort data with the arrange() command from dplyr. Initially, we sort the data by BMI. W1mod %&gt;% arrange(bmi) %&gt;% select(pidp, bmi) %&gt;% head(5) ## pidp bmi ## 1 614152207 3.581188 ## 2 1158204567 4.357708 ## 3 1292128539 10.098136 ## 4 1088805127 11.732290 ## 5 478722727 12.050592 However, we can also sort data by a number of factors. Finally, we sort by BMI in decreasing order, separately for each sex. library(tidyverse) W1mod %&gt;% arrange(a_sex, desc(bmi)) %&gt;% select(pidp, a_sex, bmi) %&gt;% head(5) ## pidp a_sex bmi ## 1 952435887 1 73.90269 ## 2 1632274047 1 66.37745 ## 3 340892847 1 65.19274 ## 4 1292157767 1 63.10072 ## 5 340443367 1 62.98222 Here, we have just printed the first five rows of this data as an example. If you wanted, you could save these ordered datasets in the working environment, the same way we saved our new datasets earlier. "],
["joining.html", "6 Join data 6.1 Introduction to joining data 6.2 Joining waves 1 and 2", " 6 Join data Prerequisite: Chapter 13 ‘Relational Data’ from R for Data Science, available at http://r4ds.had.co.nz/relational-data.html 6.1 Introduction to joining data When you work with data, it is rare that all the data you need will be confined to just one table. As a result, you will often find that you have to manipulate multiple data tables, or data frames. In order to do this, it helps to be able to join these multiple sources of data into just one table. This is very relevant for your assignment, as you are required to work with multiple waves of the Understanding Society data set. Without being able to join these waves together, you will struggle to analyse more than one wave at a time. This class will teach you a number of ways to do this. We will start by joining just two waves together in the four ways introduced in Chapter 13 of R for Data Science into one, easy to work with, table. The next class will focus on joining multiple waves together at once. 6.2 Joining waves 1 and 2 Following on from the class Read data, you should have the two waves of data we are going to join already saved in your myData folder, named UndSoc1ed and UndSoc2ed, with these loaded into the workspace saved as ReadData. Once you have loaded this workspace back into R, you are ready to join these two waves together. load(&quot;myData/ReadData.RData&quot;) As you already know, there can be several types of joins. Here, we will use each of them to join the two waves of data together, and look at the differences between them. However, first it is important to understand how joining data works. 6.2.1 The ‘key’ When we join two data frames together, we have to choose which variable we want to join them by, known as the ‘key’. As we are working with a data set that has an id number (the variable pidp in the data set) that is unique to each respondent, it makes sense to join the two waves we are using by this id number, so we can compare responses by each person in each wave of data. To do this, we use the by = “” command. 6.2.2 Inner join The first join we will use is the inner join. By using inner_join() we can join both waves together and keep the observations that are present in both data frames. This means that respondents who were in both waves 1 and 2 will be in our new data frame, but anyone who appeared in only wave 1 or wave 2 will be excluded. # Attaching the tidyverse package library(tidyverse) inner &lt;- UndSoc1ed %&gt;% inner_join(UndSoc2ed, by = &quot;pidp&quot;) We can see that this has excluded a number of respondents from both waves 1 and 2 who only appeared in one wave and not the other, as we only have 38388 observations in the our new data frame compared to 50994 in UndSoc1, and 54597 in UndSoc2. 6.2.3 Left join However, we may not want to exclude all of the respondents who do not appear in both waves. If, for example, we were working with three waves of data and wanted to compare how the answers given by respondents in wave 1 changed over time, we would want to keep answers from people who were in waves 1 and 3, even if they were not in wave 2. To do this, we can use left_join(), which will keep answers from everyone who appeared in wave 1, and exclude answers from everyone who did not. left &lt;- UndSoc1ed %&gt;% left_join(UndSoc2ed, by = &quot;pidp&quot;) To check we have done this correctly, we can compare the number of observations in UndSoc1ed and left, which should be the same. As we can see they each have 50994 observations, we can be confident our new data frame has been created successfully. If any respondents appeared in wave 1 but not wave 2, their answers for wave 2 will show as ‘NA’ values. We can have a quick look at how this new data frame looks with head(). head(left) ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 NA NA NA ## 2 68004087 1 59 2 1 60 2 ## 3 68006127 2 39 4 2 40 4 ## 4 68006135 2 17 4 NA NA NA ## 5 68006807 2 72 4 2 73 4 ## 6 68007487 2 57 1 2 58 2 6.2.4 Right join The command right_join() is very similar to left_join(), except that instead of keeping all the respondents who were in wave 1, this will keep all the respondents who appeared in wave 2 and exclude those who did not. Again, any respondents who appeared in wave 2 but not wave 1 will have their answers for wave 1 show as ‘NA’ values. right &lt;- UndSoc1ed %&gt;% right_join(UndSoc2ed, by = &quot;pidp&quot;) head(right) ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## 1 68004087 1 59 2 1 60 2 ## 2 68006127 2 39 4 2 40 4 ## 3 68006807 2 72 4 2 73 4 ## 4 68007487 2 57 1 2 58 2 ## 5 68008167 2 38 3 2 39 4 ## 6 68008171 1 51 -7 1 52 -7 6.2.5 Full join Usually, we would want all the respondents from both waves to remain in the data set, no matter if they appeared in the other waves or not. If we need to exclude any respondents from our analysis we can do this manually. We can do a full join with the full_join() command. full &lt;- UndSoc1ed %&gt;% full_join(UndSoc2ed, by = &quot;pidp&quot;) By doing a full join, our new data frame has 67203 observations compared to 50994 in wave 1 and 54597 in wave 2. This is because it includes not only all the individuals that took part in both waves 1 and 2, but also those who only took part in either wave 1 or wave 2. Now that we have joined two waves together, we could begin our analysis of these waves, if we had decided to just analyse the first couple of waves from the Understanding Society dataset. head(full) ## pidp a_sex a_dvage a_vote6 b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 NA NA NA ## 2 68004087 1 59 2 1 60 2 ## 3 68006127 2 39 4 2 40 4 ## 4 68006135 2 17 4 NA NA NA ## 5 68006807 2 72 4 2 73 4 ## 6 68007487 2 57 1 2 58 2 If you wanted to work with more than just these two waves, you could manually join each new wave to our ‘full’ data frame. However, this is a slow and cumbersome process, so the next class will teach you how to join several waves of data together at once, using iteration and loops. "],
["iteration.html", "7 Iteration 7.1 Introduction to iteration 7.2 Loading Understanding Society using iteration", " 7 Iteration Prerequisite: Chapter 21 ‘Iteration’ from R for Data Science, available at http://r4ds.had.co.nz/iteration.html 7.1 Introduction to iteration In the Understanding Society data we have seven waves and seven separate files for adult questionnaires. We will need to read them all for the data to be joined. Of course, we can read them one by one, but this is inconvenient. We will use this example to learn about iteration, one of the most important concepts in programming. You should read Chapter 21 from R for Data Science and do the exercises to learn the basics; here we will consider how we can apply iteration to our case. Iteration simply means repeating a process, and the ability to do this comes with three major benefits for coding. When you need to reproduce the same, or similar, lines of code, iteration allows you to do these all at once, reducing the number of lines of code you need to write. Additionally, if you need to change sections of your code, you only need to change the original function, rather than every line you have re-written (or copy and pasted over). Finally, if you made a mistake in your original code, using iteration means you will only have to correct the error(s) in one place, rather than many. 7.1.1 The for loop Before we focus on using iterations and loops to load multiple waves of data in at once, let’s first write a simple for loop. The for loop carries out a command within criteria you have set. Let’s say we wanted to work out what the square and cube of the numbers from 1 to 20 were. We could calculate this for each number individually, but doing this would result in 40 separate lines of code. With a simple for loop, we can instead write this as follows: n &lt;- c(1:20) for(i in 1:length(n)){ print(c(n[i], n[i]^2, n[i]^3)) } ## [1] 1 1 1 ## [1] 2 4 8 ## [1] 3 9 27 ## [1] 4 16 64 ## [1] 5 25 125 ## [1] 6 36 216 ## [1] 7 49 343 ## [1] 8 64 512 ## [1] 9 81 729 ## [1] 10 100 1000 ## [1] 11 121 1331 ## [1] 12 144 1728 ## [1] 13 169 2197 ## [1] 14 196 2744 ## [1] 15 225 3375 ## [1] 16 256 4096 ## [1] 17 289 4913 ## [1] 18 324 5832 ## [1] 19 361 6859 ## [1] 20 400 8000 7.1.2 The while loop Another type of loop you will come across, though not one we will be using to load the Understanding Society data, is the while loop. Simply put, the while loop will carry out a command while certain criteria are filled, and stop once they are not (in our example, once x &lt; 36). Let’s say, for example, we now wanted to see the square and cube of numbers from 21 to 35. We can write this in a while loop in the following way: x &lt;- 21 while (x &lt; 36) { print(c(x, x^2, x^3)) x = x + 1 } ## [1] 21 441 9261 ## [1] 22 484 10648 ## [1] 23 529 12167 ## [1] 24 576 13824 ## [1] 25 625 15625 ## [1] 26 676 17576 ## [1] 27 729 19683 ## [1] 28 784 21952 ## [1] 29 841 24389 ## [1] 30 900 27000 ## [1] 31 961 29791 ## [1] 32 1024 32768 ## [1] 33 1089 35937 ## [1] 34 1156 39304 ## [1] 35 1225 42875 7.2 Loading Understanding Society using iteration To load the Understanding Society data, let’s first consider a very simple for loop. for (i in 1:5) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 This loop goes through the values from 1 to 5 and, in each iteration, prints the number on the screen. With the Understanding Society data, we want to go from 1 to 7 (as we have seven waves) and in each iteration we want to read in the data and join it to the data from other waves. Let’s see how we can write a loop that does this. First, we need to identify the files we want to open. The dir function will return the paths and names of all the data files in our data folder that contain the pattern indresp. files &lt;- dir( # Select the folder in which the files are stored. &quot;data/UKDA-6614-tab/tab&quot;, # Tell R which pattern you want present in the files it will display. pattern = &quot;indresp&quot;, # We want this process to repeat through the entire folder. recursive = TRUE, # And finally want R to show us the entire file path, rather than just the names of the individual files. full.names = TRUE) files ## [1] &quot;data/UKDA-6614-tab/tab/bhps_w1/ba_indresp.tab&quot; ## [2] &quot;data/UKDA-6614-tab/tab/bhps_w10/bj_indresp.tab&quot; ## [3] &quot;data/UKDA-6614-tab/tab/bhps_w11/bk_indresp.tab&quot; ## [4] &quot;data/UKDA-6614-tab/tab/bhps_w12/bl_indresp.tab&quot; ## [5] &quot;data/UKDA-6614-tab/tab/bhps_w13/bm_indresp.tab&quot; ## [6] &quot;data/UKDA-6614-tab/tab/bhps_w14/bn_indresp.tab&quot; ## [7] &quot;data/UKDA-6614-tab/tab/bhps_w15/bo_indresp.tab&quot; ## [8] &quot;data/UKDA-6614-tab/tab/bhps_w16/bp_indresp.tab&quot; ## [9] &quot;data/UKDA-6614-tab/tab/bhps_w17/bq_indresp.tab&quot; ## [10] &quot;data/UKDA-6614-tab/tab/bhps_w18/br_indresp.tab&quot; ## [11] &quot;data/UKDA-6614-tab/tab/bhps_w2/bb_indresp.tab&quot; ## [12] &quot;data/UKDA-6614-tab/tab/bhps_w3/bc_indresp.tab&quot; ## [13] &quot;data/UKDA-6614-tab/tab/bhps_w4/bd_indresp.tab&quot; ## [14] &quot;data/UKDA-6614-tab/tab/bhps_w5/be_indresp.tab&quot; ## [15] &quot;data/UKDA-6614-tab/tab/bhps_w6/bf_indresp.tab&quot; ## [16] &quot;data/UKDA-6614-tab/tab/bhps_w7/bg_indresp.tab&quot; ## [17] &quot;data/UKDA-6614-tab/tab/bhps_w8/bh_indresp.tab&quot; ## [18] &quot;data/UKDA-6614-tab/tab/bhps_w9/bi_indresp.tab&quot; ## [19] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [20] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [21] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [22] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [23] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [24] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [25] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; There are 25 files as we also have data from the BHPS, not just Understanding Society. We do not need the BHPS, so we want to select only the files from Understanding Society. We can use the function str_detect from the package stringr to select only the files whose paths contain us. # stringr will return a logical vector. Note that I specify which package the function comes from without explicitly attaching it. stringr::str_detect(files, &quot;us&quot;) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE ## [23] TRUE TRUE TRUE # Now I only select the files from UndSoc files &lt;- files[stringr::str_detect(files, &quot;us&quot;)] files ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [2] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [3] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [4] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [5] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [6] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [7] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; Now we have a vector of file names we want to loop over. We can write a short loop that prints the path and files’ names. for (i in 1:7) { print(files[i]) } ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; Note that the same task can be achieved simply with: for (i in files) { print(i) } ## [1] &quot;data/UKDA-6614-tab/tab/us_w1/a_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w2/b_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w3/c_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w4/d_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w5/e_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w6/f_indresp.tab&quot; ## [1] &quot;data/UKDA-6614-tab/tab/us_w7/g_indresp.tab&quot; You will see a bit later why I wanted to loop over numbers rather than elements of the character vector. Now we need to read in the data. We can read the files in their entirety, but this is inefficient as we will only need a few variables. The function fread from the package data.table allows us to specify the variables we want to read (look back at Read Data if you need a recap here). Let’s choose the id variable (pidp), sex, age, interest in politics and net monthly income. The problem is that in each wave these variables have different names indicated by a prefix. pidp does not change and has the same name in each wave. All the other variables have a prefix a_ in wave 1, b_ in wave 2, etc. We will need to find a way to loop over not just file names in files, but also prefixes at the same time. Let’s start with creating a vector of the variable names without the prefixes. vars &lt;- c(&quot;sex&quot;, &quot;dvage&quot;, &quot;vote6&quot;, &quot;fimnnet_dv&quot;) If we want to add a prefix to the elements of this vector we can use the function paste. paste(&quot;a&quot;, vars, sep = &quot;_&quot;) ## [1] &quot;a_sex&quot; &quot;a_dvage&quot; &quot;a_vote6&quot; &quot;a_fimnnet_dv&quot; The constant letters contains all the letters of the English alphabet, so the same expression can be written as the following: paste(letters[1], vars, sep = &quot;_&quot;) ## [1] &quot;a_sex&quot; &quot;a_dvage&quot; &quot;a_vote6&quot; &quot;a_fimnnet_dv&quot; Now we can write a loop that goes through the values 1 to 7 and in each iteration reads the correct data file choosing the variables with the correct prefix. # Attach data.table for the fread function. library(data.table) for (i in 1:7) { # Create a vector of the variables with the correct prefix. varsToSelect &lt;- paste(letters[i], vars, sep = &quot;_&quot;) # Add pidp to this vector (no prefix for pidp) varsToSelect &lt;- c(&quot;pidp&quot;, varsToSelect) # Now read the data. data &lt;- fread(files[i], select = varsToSelect) # print the first line print(head(data, 1)) } ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv ## 1: 68001367 1 39 3 1400 ## pidp b_sex b_dvage b_vote6 b_fimnnet_dv ## 1: 68004087 1 60 2 1276.667 ## Read 40.2% of 49739 rows Read 49739 rows and 5 (of 3024) columns from 0.402 GB file in 00:00:04 ## pidp c_sex c_dvage c_vote6 c_fimnnet_dv ## 1: 68004087 1 61 2 914.3333 ## pidp d_sex d_dvage d_vote6 d_fimnnet_dv ## 1: 68004087 1 62 1 914.3333 ## Read 66.8% of 44903 rows Read 44903 rows and 5 (of 2583) columns from 0.310 GB file in 00:00:03 ## pidp e_sex e_dvage e_vote6 e_fimnnet_dv ## 1: 68004087 1 63 2 1015.667 ## Read 88.3% of 45290 rows Read 45290 rows and 5 (of 2060) columns from 0.263 GB file in 00:00:03 ## pidp f_sex f_dvage f_vote6 f_fimnnet_dv ## 1: 68004087 1 64 2 1007.5 ## Read 71.1% of 42217 rows Read 42217 rows and 5 (of 2799) columns from 0.321 GB file in 00:00:03 ## pidp g_sex g_dvage g_vote6 g_fimnnet_dv ## 1: 68004087 1 65 2 1258.333 Now we need to join all these data frames together, and we want to do this in the loop. It is clear what we need to do in the second and later iterations of the loop: join the data from wave 2 with the data from wave 1, and so on. But what shall we do in the first iteration? There is no data frame yet to be joined with the data from wave 1. Clearly our algorithm for the first iteration needs to be different from the algorithm for all other iterations. We will use the if … else control structure for this. In the first iteration of the loop we simply want to save the data from wave 1. In the second and other iterations we want the data to be joined with the data frame we have from the previous iteration. # Attach dplyr for the full_join function. library(dplyr) for (i in 1:7) { # Create a vector of the variables with the correct prefix. varsToSelect &lt;- paste(letters[i], vars, sep = &quot;_&quot;) # Add pidp to this vector (no prefix for pidp) varsToSelect &lt;- c(&quot;pidp&quot;, varsToSelect) # Now read the data. data &lt;- fread(files[i], select = varsToSelect) if (i == 1) { all7 &lt;- data } else { all7 &lt;- full_join(all7, data, by = &quot;pidp&quot;) } # Now we can remove data to free up memory rm(data) } ## Read 91.6% of 54597 rows Read 54597 rows and 5 (of 1615) columns from 0.233 GB file in 00:00:03 ## Read 40.2% of 49739 rows Read 49739 rows and 5 (of 3024) columns from 0.402 GB file in 00:00:04 ## Read 84.8% of 47157 rows Read 47157 rows and 5 (of 2086) columns from 0.262 GB file in 00:00:03 ## Read 66.8% of 44903 rows Read 44903 rows and 5 (of 2583) columns from 0.310 GB file in 00:00:03 ## Read 88.3% of 45290 rows Read 45290 rows and 5 (of 2060) columns from 0.263 GB file in 00:00:03 ## Read 71.1% of 42217 rows Read 42217 rows and 5 (of 2799) columns from 0.321 GB file in 00:00:03 all7 now contains the data from all seven waves. head(all7, 3) ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## 3 68006127 2 39 4 1179.5267 2 40 4 ## b_fimnnet_dv c_sex c_dvage c_vote6 c_fimnnet_dv d_sex d_dvage d_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 1276.667 1 61 2 914.3333 1 62 1 ## 3 1115.993 2 41 4 1175.6666 2 43 4 ## d_fimnnet_dv e_sex e_dvage e_vote6 e_fimnnet_dv f_sex f_dvage f_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 914.3333 1 63 2 1015.667 1 64 2 ## 3 851.6666 2 43 4 1025.276 2 44 4 ## f_fimnnet_dv g_sex g_dvage g_vote6 g_fimnnet_dv ## 1 NA NA NA NA NA ## 2 1007.500 1 65 2 1258.333 ## 3 1108.833 2 45 4 385.000 We will now save this file for future use using the saveRDS function in the myData folder (make sure first you have this folder on your computer). We went through saving individual files in Read Data, covering saving objects as RDS files at http://abessudnov.net/dataanalysis3/readdata.html#saving-an-object-as-an-rds-file saveRDS(all7, &quot;myData/all7.rds&quot;) "],
["tidy-data.html", "8 Tidy data 8.1 Long and wide formats 8.2 Cleaning the data", " 8 Tidy data For this class please read ch.12 on Tidy Data from R for Data Science – http://r4ds.had.co.nz/tidy-data.html. In the previous part of the course (joiningData.Rmd) we learned how to join together data from seven waves of the Understanding Society. Let us open this data set. UndSoc &lt;- readRDS(&quot;myData/all7.rds&quot;) head(UndSoc) ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## 3 68006127 2 39 4 1179.5267 2 40 4 ## 4 68006135 2 17 4 130.0000 NA NA NA ## 5 68006807 2 72 4 933.8135 2 73 4 ## 6 68007487 2 57 1 400.0000 2 58 2 ## b_fimnnet_dv c_sex c_dvage c_vote6 c_fimnnet_dv d_sex d_dvage d_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 1276.66663 1 61 2 914.3333 1 62 1 ## 3 1115.99341 2 41 4 1175.6666 2 43 4 ## 4 NA 2 19 4 1100.0000 2 21 2 ## 5 1145.27893 2 74 4 1146.7035 2 75 4 ## 6 16.66666 2 59 4 475.0000 2 60 1 ## d_fimnnet_dv e_sex e_dvage e_vote6 e_fimnnet_dv f_sex f_dvage f_vote6 ## 1 NA NA NA NA NA NA NA NA ## 2 914.3333 1 63 2 1015.6667 1 64 2 ## 3 851.6666 2 43 4 1025.2756 2 44 4 ## 4 977.7525 2 21 4 823.0209 NA NA NA ## 5 1405.1293 2 76 4 15000.0000 2 77 4 ## 6 666.6168 NA NA NA NA NA NA NA ## f_fimnnet_dv g_sex g_dvage g_vote6 g_fimnnet_dv ## 1 NA NA NA NA NA ## 2 1007.500 1 65 2 1258.3334 ## 3 1108.833 2 45 4 385.0000 ## 4 NA 2 23 -7 909.2457 ## 5 904.209 2 78 3 996.6353 ## 6 NA NA NA NA NA Now we will work on how these data can be represented and prepared for the analysis. Please read ch.12 on Tidy Data from the R for Data Science Book – http://r4ds.had.co.nz/tidy-data.html. 8.1 Long and wide formats Let us keep only a few observations and columns in the data and more closely look at its structure. UndSocExample &lt;- UndSoc %&gt;% filter(pidp == 68001367 | pidp == 68004087) %&gt;% select(pidp, a_sex: b_fimnnet_dv) UndSocExample ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## b_fimnnet_dv ## 1 NA ## 2 1276.667 These are the data for two individuals only in waves 1 and 2. The data are represented in the wide format. This means that we have one row for each individual, and data from different waves are recorded in several columns. For example, the data on sex from wave 1 is in column a_sex and the data on sex from wave is in b_sex. You will find this representation of the data common in longitudinal data sets. It may be convenient for certain purposes, but it is generally recommended to keep the data in the long format (that corresponds to the tidy data principles as described in the R for Data Science book). To move from the wide to the long format we can use the function melt and cast functions from the reshape2 package. require(reshape2) # First we &quot;melt&quot; the data frame. UndSocExampleMolten &lt;- UndSocExample %&gt;% melt(id = &quot;pidp&quot;) UndSocExampleMolten ## pidp variable value ## 1 68001367 a_sex 1.0000 ## 2 68004087 a_sex 1.0000 ## 3 68001367 a_dvage 39.0000 ## 4 68004087 a_dvage 59.0000 ## 5 68001367 a_vote6 3.0000 ## 6 68004087 a_vote6 2.0000 ## 7 68001367 a_fimnnet_dv 1400.0000 ## 8 68004087 a_fimnnet_dv 802.0833 ## 9 68001367 b_sex NA ## 10 68004087 b_sex 1.0000 ## 11 68001367 b_dvage NA ## 12 68004087 b_dvage 60.0000 ## 13 68001367 b_vote6 NA ## 14 68004087 b_vote6 2.0000 ## 15 68001367 b_fimnnet_dv NA ## 16 68004087 b_fimnnet_dv 1276.6666 # Next I want to split the column variable into a column indicating wave and a column indicating variable name. # I will use the function separate() from tidyr. UndSocExampleSep &lt;- UndSocExampleMolten %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) UndSocExampleSep ## pidp wave variable value ## 1 68001367 a sex 1.0000 ## 2 68004087 a sex 1.0000 ## 3 68001367 a dvage 39.0000 ## 4 68004087 a dvage 59.0000 ## 5 68001367 a vote6 3.0000 ## 6 68004087 a vote6 2.0000 ## 7 68001367 a fimnnet 1400.0000 ## 8 68004087 a fimnnet 802.0833 ## 9 68001367 b sex NA ## 10 68004087 b sex 1.0000 ## 11 68001367 b dvage NA ## 12 68004087 b dvage 60.0000 ## 13 68001367 b vote6 NA ## 14 68004087 b vote6 2.0000 ## 15 68001367 b fimnnet NA ## 16 68004087 b fimnnet 1276.6666 # We have a problem here because one of our variables (fimnnet_dv) has _ in the name and we do not want to separate by it. To avoid this problem we need to add the argument extra = &quot;merge&quot;&quot; in separate(). UndSocExampleSep &lt;- UndSocExampleMolten %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;, extra = &quot;merge&quot;) UndSocExampleSep ## pidp wave variable value ## 1 68001367 a sex 1.0000 ## 2 68004087 a sex 1.0000 ## 3 68001367 a dvage 39.0000 ## 4 68004087 a dvage 59.0000 ## 5 68001367 a vote6 3.0000 ## 6 68004087 a vote6 2.0000 ## 7 68001367 a fimnnet_dv 1400.0000 ## 8 68004087 a fimnnet_dv 802.0833 ## 9 68001367 b sex NA ## 10 68004087 b sex 1.0000 ## 11 68001367 b dvage NA ## 12 68004087 b dvage 60.0000 ## 13 68001367 b vote6 NA ## 14 68004087 b vote6 2.0000 ## 15 68001367 b fimnnet_dv NA ## 16 68004087 b fimnnet_dv 1276.6666 # Next we &quot;cast&quot; the molten data frame into the format we want. UndSocExampleLong &lt;- UndSocExampleSep %&gt;% dcast(pidp + wave ~ variable) UndSocExampleLong ## pidp wave dvage fimnnet_dv sex vote6 ## 1 68001367 a 39 1400.0000 1 3 ## 2 68001367 b NA NA NA NA ## 3 68004087 a 59 802.0833 1 2 ## 4 68004087 b 60 1276.6666 1 2 Now the data are in the “long format”. This means that we have as many rows for each individual as the number of waves, a variable indicating wave, and all other variables are in columns. In most cases with longitudinal data, the long format is easier to work with. What if we want to convert the data back to the wide format? # First melt UndSocExampleMolten2 &lt;- UndSocExampleLong %&gt;% melt(id = c(&quot;pidp&quot;, &quot;wave&quot;)) UndSocExampleMolten2 ## pidp wave variable value ## 1 68001367 a dvage 39.0000 ## 2 68001367 b dvage NA ## 3 68004087 a dvage 59.0000 ## 4 68004087 b dvage 60.0000 ## 5 68001367 a fimnnet_dv 1400.0000 ## 6 68001367 b fimnnet_dv NA ## 7 68004087 a fimnnet_dv 802.0833 ## 8 68004087 b fimnnet_dv 1276.6666 ## 9 68001367 a sex 1.0000 ## 10 68001367 b sex NA ## 11 68004087 a sex 1.0000 ## 12 68004087 b sex 1.0000 ## 13 68001367 a vote6 3.0000 ## 14 68001367 b vote6 NA ## 15 68004087 a vote6 2.0000 ## 16 68004087 b vote6 2.0000 # Unite the columns UndSocExampleUnited &lt;- UndSocExampleMolten2 %&gt;% unite(&quot;variable&quot;, c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) UndSocExampleUnited ## pidp variable value ## 1 68001367 a_dvage 39.0000 ## 2 68001367 b_dvage NA ## 3 68004087 a_dvage 59.0000 ## 4 68004087 b_dvage 60.0000 ## 5 68001367 a_fimnnet_dv 1400.0000 ## 6 68001367 b_fimnnet_dv NA ## 7 68004087 a_fimnnet_dv 802.0833 ## 8 68004087 b_fimnnet_dv 1276.6666 ## 9 68001367 a_sex 1.0000 ## 10 68001367 b_sex NA ## 11 68004087 a_sex 1.0000 ## 12 68004087 b_sex 1.0000 ## 13 68001367 a_vote6 3.0000 ## 14 68001367 b_vote6 NA ## 15 68004087 a_vote6 2.0000 ## 16 68004087 b_vote6 2.0000 # And now cast UndSocExampleWide &lt;- UndSocExampleUnited %&gt;% dcast(pidp ~ variable) UndSocExampleWide ## pidp a_dvage a_fimnnet_dv a_sex a_vote6 b_dvage b_fimnnet_dv b_sex ## 1 68001367 39 1400.0000 1 3 NA NA NA ## 2 68004087 59 802.0833 1 2 60 1276.667 1 ## b_vote6 ## 1 NA ## 2 2 We can also restructure the data using the gather and spread functions from the tidyr package (part of tidyverse). gather is roughy equivalent to melt and spread is roughy equivalent to dcast. Moving from wide to long: UndSocExample ## pidp a_sex a_dvage a_vote6 a_fimnnet_dv b_sex b_dvage b_vote6 ## 1 68001367 1 39 3 1400.0000 NA NA NA ## 2 68004087 1 59 2 802.0833 1 60 2 ## b_fimnnet_dv ## 1 NA ## 2 1276.667 # This &quot;melts&quot; the data frame. UndSocExample %&gt;% gather(a_sex:b_fimnnet_dv, key = &quot;variable&quot;, value = &quot;value&quot;) ## pidp variable value ## 1 68001367 a_sex 1.0000 ## 2 68004087 a_sex 1.0000 ## 3 68001367 a_dvage 39.0000 ## 4 68004087 a_dvage 59.0000 ## 5 68001367 a_vote6 3.0000 ## 6 68004087 a_vote6 2.0000 ## 7 68001367 a_fimnnet_dv 1400.0000 ## 8 68004087 a_fimnnet_dv 802.0833 ## 9 68001367 b_sex NA ## 10 68004087 b_sex 1.0000 ## 11 68001367 b_dvage NA ## 12 68004087 b_dvage 60.0000 ## 13 68001367 b_vote6 NA ## 14 68004087 b_vote6 2.0000 ## 15 68001367 b_fimnnet_dv NA ## 16 68004087 b_fimnnet_dv 1276.6666 # Next we want to split the &quot;variable&quot; column and &quot;cast&quot; in the long format UndSocExample %&gt;% gather(a_sex:b_vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;, extra = &quot;merge&quot;) %&gt;% spread(key = variable, value = value) ## pidp b_fimnnet_dv wave dvage fimnnet_dv sex vote6 ## 1 68001367 NA a 39 1400.0000 1 3 ## 2 68001367 NA b NA NA NA NA ## 3 68004087 1276.667 a 59 802.0833 1 2 ## 4 68004087 1276.667 b 60 NA 1 2 If we want to move from long to wide: UndSocExampleLong ## pidp wave dvage fimnnet_dv sex vote6 ## 1 68001367 a 39 1400.0000 1 3 ## 2 68001367 b NA NA NA NA ## 3 68004087 a 59 802.0833 1 2 ## 4 68004087 b 60 1276.6666 1 2 UndSocExampleLong %&gt;% gather(dvage:vote6, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% unite(&quot;variable&quot;, c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;) %&gt;% spread(key = variable, value = value) ## pidp a_dvage a_fimnnet_dv a_sex a_vote6 b_dvage b_fimnnet_dv b_sex ## 1 68001367 39 1400.0000 1 3 NA NA NA ## 2 68004087 59 802.0833 1 2 60 1276.667 1 ## b_vote6 ## 1 NA ## 2 2 Exercise. Reshape the full UndSoc data frame from wide to long format. Call the object where you will store the result UndSocLong. Solution: UndSocLong &lt;- UndSoc %&gt;% gather(a_sex:g_fimnnet_dv, key = &quot;variable&quot;, value = &quot;value&quot;) %&gt;% separate(variable, into = c(&quot;wave&quot;, &quot;variable&quot;), sep = &quot;_&quot;, extra = &quot;merge&quot;) %&gt;% spread(key = variable, value = value) head(UndSocLong, 5) ## pidp wave dvage fimnnet_dv sex vote6 ## 1 22445 a NA NA NA NA ## 2 22445 b NA NA NA NA ## 3 22445 c NA NA NA NA ## 4 22445 d 27 1140.000 2 2 ## 5 22445 e 28 1602.667 2 2 8.2 Cleaning the data Before we begin the analysis we want to make sure that the data have been cleaned and all the missing values have been correctly identified. It usually makes sense to separate the cleaning and analysis stages into separate scripts. Let us explore the data set we have. Note that if we had not converted the data into the long format we would have to tabulate and clean each variable seven times. summary(UndSocLong) ## pidp wave dvage fimnnet_dv ## Min. :2.244e+04 Length:584703 Min. : -9.00 Min. :-42904 ## 1st Qu.:4.086e+08 Class :character 1st Qu.: 32.00 1st Qu.: 630 ## Median :7.493e+08 Mode :character Median : 46.00 Median : 1159 ## Mean :7.973e+08 Mean : 47.09 Mean : 1383 ## 3rd Qu.:1.224e+09 3rd Qu.: 61.00 3rd Qu.: 1800 ## Max. :1.653e+09 Max. :104.00 Max. : 15000 ## NA&#39;s :249806 NA&#39;s :249806 ## sex vote6 ## Min. :-9.00 Min. :-10.00 ## 1st Qu.: 1.00 1st Qu.: 2.00 ## Median : 2.00 Median : 3.00 ## Mean : 1.54 Mean : 1.82 ## 3rd Qu.: 2.00 3rd Qu.: 4.00 ## Max. : 2.00 Max. : 4.00 ## NA&#39;s :249806 NA&#39;s :249806 table(UndSocLong$wave) ## ## a b c d e f g ## 83529 83529 83529 83529 83529 83529 83529 table(UndSocLong$dvage) ## ## -9 -2 -1 16 17 18 19 20 21 22 23 24 25 26 27 ## 19 6 34 5735 5769 5536 5350 5188 5000 4779 4668 4537 4555 4556 4610 ## 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 ## 4742 4836 5129 5181 5286 5387 5380 5512 5591 5519 5765 5896 6155 6274 6422 ## 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 ## 6291 6450 6489 6316 6263 6187 6119 6013 5901 5727 5701 5483 5406 5193 5042 ## 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 ## 5052 4856 4782 4962 4995 5013 4999 4846 4814 4666 4435 4210 3914 3707 3504 ## 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 ## 3316 3130 2977 2749 2618 2452 2241 2106 1886 1749 1599 1390 1211 988 860 ## 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 ## 683 547 453 344 243 172 131 92 80 41 36 25 15 6 2 ## 103 104 ## 1 1 table(UndSocLong$sex) ## ## -9 -1 1 2 ## 2 1 154045 180849 table(UndSocLong$vote6) ## ## -10 -9 -7 -2 -1 1 2 3 4 ## 4656 366 24752 431 358 30981 102212 86790 84351 summary(UndSocLong$fimnnet_dv) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## -42904 630 1159 1383 1800 15000 249806 Note the negative values for dvage, sex and vote6. These are missing values that need to be coded as missing. UndSocLong &lt;- UndSocLong %&gt;% mutate(dvage = ifelse(dvage &gt; 0, dvage, NA)) %&gt;% mutate(sex = ifelse(sex &gt; 0, sex, NA)) %&gt;% mutate(vote6 = ifelse(vote6 &gt; 0, vote6, NA)) table(UndSocLong$dvage) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ## 5735 5769 5536 5350 5188 5000 4779 4668 4537 4555 4556 4610 4742 4836 5129 ## 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## 5181 5286 5387 5380 5512 5591 5519 5765 5896 6155 6274 6422 6291 6450 6489 ## 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ## 6316 6263 6187 6119 6013 5901 5727 5701 5483 5406 5193 5042 5052 4856 4782 ## 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 4962 4995 5013 4999 4846 4814 4666 4435 4210 3914 3707 3504 3316 3130 2977 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## 2749 2618 2452 2241 2106 1886 1749 1599 1390 1211 988 860 683 547 453 ## 91 92 93 94 95 96 97 98 99 100 101 102 103 104 ## 344 243 172 131 92 80 41 36 25 15 6 2 1 1 table(UndSocLong$sex) ## ## 1 2 ## 154045 180849 table(UndSocLong$vote6) ## ## 1 2 3 4 ## 30981 102212 86790 84351 We also have negative values for income (fimnnet_dv), but we will leave as it is for now. We may also want to code sex as “male” and “female” and assign meaningful labels to vote6. UndSocLongClean &lt;- UndSocLong %&gt;% mutate(sex = recode(sex, &quot;1&quot; = &quot;male&quot;, &quot;2&quot; = &quot;female&quot;)) %&gt;% mutate(vote6 = recode(vote6, &quot;1&quot; = &quot;very&quot;, &quot;2&quot; = &quot;fairly&quot;, &quot;3&quot; = &quot;not very&quot;, &quot;4&quot; = &quot;not al all&quot;)) head(UndSocLongClean, 10) ## pidp wave dvage fimnnet_dv sex vote6 ## 1 22445 a NA NA &lt;NA&gt; &lt;NA&gt; ## 2 22445 b NA NA &lt;NA&gt; &lt;NA&gt; ## 3 22445 c NA NA &lt;NA&gt; &lt;NA&gt; ## 4 22445 d 27 1140.000 female fairly ## 5 22445 e 28 1602.667 female fairly ## 6 22445 f 29 2012.000 female fairly ## 7 22445 g 30 1840.000 female very ## 8 29925 a NA NA &lt;NA&gt; &lt;NA&gt; ## 9 29925 b NA NA &lt;NA&gt; &lt;NA&gt; ## 10 29925 c NA NA &lt;NA&gt; &lt;NA&gt; saveRDS(UndSocLongClean, &quot;myData/all7clean.rds&quot;) "],
["datavis.html", "9 Data visualisation 9.1 Reading in the data 9.2 Visualising one quantitative variable 9.3 Visualising one categorical variable 9.4 Visualising two quantitative variables 9.5 Visualising one categorical and one quantitative variable 9.6 Visualising two categorical variables 9.7 Showing the relationships by group", " 9 Data visualisation Pre-requisite for this class: ch.3 (“Data visualisation”) from R for Data Science - http://r4ds.had.co.nz/data-visualisation.html At home you learned about the basic principles of data visualisation in R with the ggplot2 package. Let us see how we can apply this to the Understanding Society data set. Personally I can never remember all the details of the ggplot2 syntax. I often use the ready-made “recipes” from the R Graphics Cookbook by W.Chang – https://www.amazon.co.uk/R-Graphics-Cookbook-Winston-Chang/dp/1449316956/. The 2nd edition is coming out later this year – https://www.amazon.co.uk/Graphics-Cookbook-2e-Winston-Chang/dp/1491978600 . You may also find Winston Chang’s website useful (and not only for graphics) - http://www.cookbook-r.com . 9.1 Reading in the data First let us read in the data we used in week 2 when we learned about dplyr (a short version of the wave 1 data) and recreate the measures for weight, height and BMI. library(tidyverse) library(data.table) W1 &lt;- readRDS(&quot;myData/W1mod.rds&quot;) head(W1, 3) ## # A tibble: 3 x 15 ## pidp a_sex a_dvage a_ukborn a_hlht a_hlhtf a_hlhti a_hlhtc a_hlwt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 68001367 1 39 1 1 6 0 -8 1 ## 2 68004087 1 59 5 1 5 11 -8 2 ## 3 68006127 2 39 1 1 5 1 -8 1 ## # ... with 6 more variables: a_hlwts &lt;int&gt;, a_hlwtp &lt;int&gt;, a_hlwtk &lt;int&gt;, ## # heightcm &lt;dbl&gt;, weightkg &lt;dbl&gt;, bmi &lt;dbl&gt; 9.2 Visualising one quantitative variable Exercise. Visualise the distribution of the BMI with ggplot2. Which statistical graphs would be appropriate for this? 9.2.1 Histogram. ggplot(W1, aes(x=bmi)) + geom_histogram(bins = 100) + xlab(&quot;Body mass index&quot;) 9.2.2 Density chart. ggplot(W1, aes(x=bmi)) + geom_density() + xlab(&quot;Body mass index&quot;) 9.3 Visualising one categorical variable Exercise. Visualise the distribution of a_ukborn with ggplot2. Which statistical graphs would be appropriate for this? 9.3.1 Bar plot. table(W1$a_ukborn) ## ## -9 -2 -1 1 2 3 4 5 ## 6 2 8 33480 3567 2154 2033 9744 W1 &lt;- W1 %&gt;% mutate(a_ukborn = ifelse(a_ukborn &gt; 0, a_ukborn, NA)) %&gt;% mutate(cbirth = recode(a_ukborn, &quot;1&quot; = &quot;England&quot;, &quot;2&quot; = &quot;Scotland&quot;, &quot;3&quot; = &quot;Wales&quot;, &quot;4&quot; = &quot;Northern Ireland&quot;, &quot;5&quot; = &quot;Not UK&quot;)) table(W1$cbirth) ## ## England Northern Ireland Not UK Scotland ## 33480 2033 9744 3567 ## Wales ## 2154 W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth)) + geom_bar() + xlab(&quot;Country of birth&quot;) table(W1$cbirth, useNA = &quot;always&quot;) ## ## England Northern Ireland Not UK Scotland ## 33480 2033 9744 3567 ## Wales &lt;NA&gt; ## 2154 16 9.4 Visualising two quantitative variables Exercise. Visualise the joint distribution of weight (in kg) and height (in cm). In your chart show the regression line and the nonparametric smoothing line. ggplot(W1, aes(x = weightkg, y= heightcm)) + geom_point() + geom_smooth() + stat_smooth(method=lm) 9.5 Visualising one categorical and one quantitative variable Exercise. Visualise the distribution of BMI for a) men and women, b) different age groups. # Coding a categorical variable for age groups table(W1$a_dvage, useNA = &quot;always&quot;) ## ## 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ## 937 864 787 798 786 738 756 786 806 791 827 849 878 936 914 ## 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 ## 884 879 917 864 928 983 923 976 1051 1054 1032 1043 935 968 987 ## 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 ## 940 941 917 889 873 824 817 765 803 722 761 703 756 666 662 ## 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 ## 820 806 775 685 621 646 591 521 563 571 500 498 443 411 380 ## 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 ## 368 356 338 294 287 267 225 207 166 147 132 108 80 73 54 ## 91 92 93 94 95 96 97 98 99 100 101 &lt;NA&gt; ## 38 27 20 21 14 14 4 3 2 1 1 0 W1 &lt;- W1 %&gt;% mutate(agegr = ifelse(a_dvage &lt; 31, &quot;16-30&quot;, ifelse(a_dvage &gt; 30 &amp; a_dvage &lt; 46, &quot;31-45&quot;, ifelse(a_dvage &gt; 45 &amp; a_dvage &lt; 61, &quot;46-60&quot;, &quot;&gt;60&quot;)))) %&gt;% mutate(agegr = factor(agegr, c(&quot;16-30&quot;, &quot;31-45&quot;, &quot;46-60&quot;, &quot;&gt;60&quot;))) ggplot(W1, aes(x = agegr, y= bmi)) + geom_boxplot() + xlab(&quot;Age group&quot;) + ylab(&quot;Body mass index&quot;) 9.6 Visualising two categorical variables Exercise. Use facets to visualise the distribution of a_ukborn by age group. W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth)) + geom_bar() + xlab(&quot;Country of birth&quot;) + facet_wrap(~ agegr) Alternatively you can do a jitter plot, but in our case it wouldn’t look nice. W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x=cbirth, y = agegr)) + geom_jitter() + xlab(&quot;Country of birth&quot;) + ylab(&quot;Age group&quot;) 9.7 Showing the relationships by group Exercise. Use facets to visualise the association between age and BMI by country of birth. W1 %&gt;% filter(!is.na(cbirth)) %&gt;% ggplot(aes(x = a_dvage, y= bmi)) + geom_point() + geom_smooth() + facet_wrap(~ cbirth) "],
["datavis2.html", "10 Data visualisation 2 10.1 Visualising income", " 10 Data visualisation 2 Pre-requisite for this class: ch.3 (“Data visualisation”) from R for Data Science - http://r4ds.had.co.nz/data-visualisation.html Also see the ggplot2 cheat sheet - https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf At the previous class we looked at some simple data visualisation techniques (see http://abessudnov.net/dataanalysis3/datavis.html). Now we will explore how we can visualise longitudinal data. First we want to read in the data frame we created when we learned to join and tidy data. UndSocLong &lt;- readRDS(&quot;myData/all7clean.rds&quot;) 10.1 Visualising income Now we want to visualise the distribution of income. There are several ways of doing this. First, we can create box plots for each wave. ggplot(UndSocLong, aes(x = wave, y= fimnnet_dv)) + geom_boxplot() + xlab(&quot;Wave&quot;) + ylab(&quot;Net monthly income&quot;) The chart does not look nice because of the outliers. We can either remove the outliers or display only a specified range of the box plots. ggplot(UndSocLong, aes(x = wave, y= fimnnet_dv)) + geom_boxplot() + xlab(&quot;Wave&quot;) + ylab(&quot;Net monthly income&quot;) + ylim(-500, 5000) We can see that the median income has been slowly increasing. Another way to display these data is a density plot. ggplot(UndSocLong, aes(x = fimnnet_dv)) + geom_density() + xlab(&quot;Net monthly income&quot;) + xlim(-500, 5000) We see a peak at zero incomes, and for positive incomes the distribution is close to normal. We can also create this chart for each wave separately. ggplot(UndSocLong, aes(x = fimnnet_dv)) + geom_density() + xlab(&quot;Net monthly income&quot;) + xlim(-500, 5000) + facet_wrap(~ wave) Now we may want to visualise the change of income across the waves. We can plot the income trajectories for each individual in the data set. Let us do this for the first five individuals. # 5 individuals, 7 waves: 5*7 = 35 first5 &lt;- UndSocLong %&gt;% slice(1:35) %&gt;% select(pidp, wave, fimnnet_dv) kable(first5) pidp wave fimnnet_dv 22445 a NA 22445 b NA 22445 c NA 22445 d 1140.000 22445 e 1602.667 22445 f 2012.000 22445 g 1840.000 29925 a NA 29925 b NA 29925 c NA 29925 d 0.000 29925 e NA 29925 f 2537.080 29925 g 2076.867 76165 a NA 76165 b NA 76165 c NA 76165 d NA 76165 e NA 76165 f NA 76165 g 1804.167 223725 a NA 223725 b NA 223725 c NA 223725 d NA 223725 e NA 223725 f NA 223725 g 3066.602 280165 a NA 280165 b 1183.872 280165 c 2367.884 280165 d 2828.061 280165 e 2324.167 280165 f 2335.695 280165 g 3049.700 ggplot(first5, aes(x = wave, y = fimnnet_dv, colour = as.factor(pidp))) + geom_point(na.rm = TRUE) + geom_line(aes(group = pidp), na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Year&quot;) This chart nicely illustrates individual income trajectories, but if we try this for even 100 people the chart will be a complete mess. UndSocLong %&gt;% slice(1:700) %&gt;% ggplot(aes(x = wave, y = fimnnet_dv, group = pidp)) + geom_point(na.rm = TRUE) + geom_line(na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Wave&quot;) Instead we can visualise summary statistics, such as mean or median. For a variable with outliers such as income median would be a better summary. # First we create a data frame of medians. medians &lt;- UndSocLong %&gt;% group_by(wave) %&gt;% summarise( medianIncome = median(fimnnet_dv, na.rm = TRUE) ) kable(medians) wave medianIncome a 1011.622 b 1087.900 c 1150.000 d 1183.333 e 1200.000 f 1231.594 g 1299.812 # Then visualize. # We need to add group = 1 because wave is not numeric ggplot(medians, aes(x = wave, y = medianIncome, group = 1)) + geom_point() + geom_line() + ylab(&quot;Median net monthly income&quot;) + xlab(&quot;Wave&quot;) There are a number of things we may want to do with this chart. First, we may want to change wave to year. Second, we may want to display confidence intervals for the point estimates. First, let us create a variable for year. We need to do this in the original data frame. For each wave in the Understanding Society, the data were collected for two years. So for Wave 1 the field work was conducted in 2009 and 2010. For simplicity, I will code the first year only. UndSocLong &lt;- UndSocLong %&gt;% mutate(year = recode(wave, &quot;a&quot; = &quot;2009&quot;, &quot;b&quot; = &quot;2010&quot;, &quot;c&quot; = &quot;2011&quot;, &quot;d&quot; = &quot;2012&quot;, &quot;e&quot; = &quot;2013&quot;, &quot;f&quot; = &quot;2014&quot;, &quot;g&quot; = &quot;2015&quot;)) %&gt;% mutate(year = as.numeric(year)) Producing confidence intervals for the median is not straightforward (you need to use statistical simulation or some other statistical tricks) so I’ll use the mean instead. UndSocLong %&gt;% group_by(year) %&gt;% summarise( # I use the function t.test to get the means and standard errors meanIncome = t.test(fimnnet_dv)$estimate, # Here I calculate the 95% confidence interval lowerIncome = t.test(fimnnet_dv)$conf.int[1], upperIncome = t.test(fimnnet_dv)$conf.int[2] ) %&gt;% # and now I visualise ggplot(aes(x = year, y = meanIncome)) + geom_point() + geom_line() + geom_ribbon(aes(ymin=lowerIncome, ymax=upperIncome), alpha=0.2) + ylab(&quot;Median net monthly income&quot;) + xlab(&quot;Year&quot;) The confidence intervals are quite wide. This is not surprising given our sample size. Another chart we can produce is not only for the medians (or means), but for different quantiles. Let us take the following quantiles: 0.01, 0.05, 0.1, 0.5. 0.9, 0.95, 0.99. This will show the change in income for the 1% poorest, 5% poorest, 10% poorest, etc. This can be done in several ways. If we use summarise to produce multiple quantiles it can get clumsy. UndSocLong %&gt;% group_by(year) %&gt;% summarise( quant1 = quantile(fimnnet_dv, 0.01, na.rm = TRUE), quant5 = quantile(fimnnet_dv, 0.05, na.rm = TRUE), quant10 = quantile(fimnnet_dv, 0.1, na.rm = TRUE), quant50 = quantile(fimnnet_dv, 0.5, na.rm = TRUE), quant90 = quantile(fimnnet_dv, 0.9, na.rm = TRUE), quant95 = quantile(fimnnet_dv, 0.95, na.rm = TRUE), quant99 = quantile(fimnnet_dv, 0.99, na.rm = TRUE) ) %&gt;% ungroup() %&gt;% # Now I need to convert this to a long format gather(quantile, value, quant1:quant99) %&gt;% # and plot ggplot(aes(x = year, y = value, colour = quantile)) + geom_point(na.rm = TRUE) + geom_line(na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Year&quot;) A more economical way to write the code is the following. This time I will also select only people with positive net incomes. library(broom) UndSocLong %&gt;% filter(fimnnet_dv &gt; 0) %&gt;% nest(-year) %&gt;% mutate(Quantiles = map(data, ~ quantile(.$fimnnet_dv, c(0.01, 0.05, 0.1, 0.5, 0.9, 0.95, 0.99)))) %&gt;% unnest(map(Quantiles, tidy)) %&gt;% ggplot(aes(x = year, y = x, colour = names)) + geom_point(na.rm = TRUE) + geom_line(na.rm = TRUE) + ylab(&quot;Net monthly income&quot;) + xlab(&quot;Year&quot;) "],
["rmarkdown.html", "11 R Markdown", " 11 R Markdown For this class read ch.27 (“R Markdown”) from R for Data Science - http://r4ds.had.co.nz/r-markdown.html The traditional approach for statistical data analysis is to analyse the data and write up the results separately. For example, you may conduct your analysis in R and then copy the output to Word and write up your results there. This is an error prone approach. The code and the results are not synchronised so that if you change your code the results will not change automatically. You can also make mistakes when copying the results. R Markdown was designed to combine statistical analysis and communication into a single framework. The code and the results are combined in a single document, and you can also add text, external tables and images if you want. You can use R Markdown to produce documents in different formats (html, Word, pdf, presentation slides). This website has been produced using R Markdown. There are many places on the web where you can learn the basics of R Markdown and there is no point for me to repeat this here. Please see ch.27 from R for Data Science (http://r4ds.had.co.nz/r-markdown.html) and the official R Markdown website (https://rmarkdown.rstudio.com) and follow the links. You can also check this webpage: https://stat545.com/block007_first-use-rmarkdown.html (this is part of a course at the University of British Columbia that is similar to our module, but somewhat more advanced). Here I will focus on a few things that are specifically relevant for your reports. You can knit your reports in either pdf or Word formats. If you are going to use Word you will not be able to use the stargazer package for regression output. You may try to use a combination of the packages memisc and pander to achieve the same result (see https://stackoverflow.com/questions/24342162/regression-tables-in-markdown-format-for-flexible-use-in-r-markdown-v2), but I haven’t tried this and I cannot guarantee that it will work. Also see https://rmarkdown.rstudio.com/articles_docx.html If you want to knit as pdf you will need to install LaTeX first (https://www.latex-project.org). Install LaTeX (complete version), restart your computer, restart R Studio and it should all work automatically. If you knit as pdf with LaTeX stargazer will work just fine, but you need to set the results argument to ‘asis’ and run stargazer in a separate R chunk. The code will look something like ```{r results = 'asis'} stargazer(m1, m2, m3, m4, type = \"latex\") ``` You need to include all your code in your report. You do not need to include messages and warnings. You may also want to use cache to speed up rendering of your document. To achieve this result include in the beginning of your R Mardown file an R chunk setting the following global options. ```{r setup} knitr::opts_chunk$set(echo = TRUE) knitr::opts_chunk$set(message = FALSE) knitr::opts_chunk$set(warning = FALSE) knitr::opts_chunk$set(cache = TRUE) ``` If you experience problems with caching switch it to FALSE. To knit a document you can use a button in R Studio. In my experience, sometimes it does not work as intended. Then you can use the command line: rmarkdown::render(&quot;your_file.Rmd&quot;, &quot;rmarkdown::word_document&quot;) rmarkdown::render(&quot;your_file.Rmd&quot;, &quot;rmarkdown::pdf_document&quot;) You will want to include a bibliography in your report. An easy way to do this is simply to type it in the end of your document. However, this is not the most efficient way of doing this. I recommend you use Zotero for your bibliographies. You will also be able to use Zotero for essays for other modules and for your dissertation, even if you do not use R or R Markdown and write everything in Word. Once you master Zotero referencing and creating bibliographies will become much easier. Go to the Zotero website (https://www.zotero.org) and create an acount. Download and install the Zotero client for your computer (https://www.zotero.org/download/). Download and install a Zotero plugin for your web browser. Once you have done this you will be able to automatically save references to your Zotero libraries from Google Scholar and other sources. You can use Zotero with Word to reference and automatically create bibliographies. This is not relevant for this module, but for other modules and for your dissertation this is a very useful skill. To learn how to do this see https://www.zotero.org/support/word_processor_integration To use Zotero with R Markdown you need to do the following. Once you have added all the references to your library, export it as a bib file (File -&gt; Export Library -&gt; choose BibTex as the format). Save your bib file in the same folder as your R Markdown document. To learn how to reference and cite in R Markdown see https://rmarkdown.rstudio.com/authoring_bibliographies_and_citations.html To include a bibliography add the following line to the YAML header of your R Markdown document: bibliography: your_bibfile_name.bib The file example.Rmd available in the Github repo shows the minimal example of referencing and creating a bibliography with one source (see https://raw.githubusercontent.com/abessudnov/dataanalysis3/master/example.Rmd). The associated bib file is available here: https://raw.githubusercontent.com/abessudnov/dataanalysis3/master/example.bib. The bib file can be opened and edited in any text editor and you can also use special software to do this, such as JabRef (http://www.jabref.org). "],
["modelling.html", "12 Modelling 12.1 Cross-sectional analysis 12.2 Longitudinal analysis 12.3 Further reading", " 12 Modelling Pre-requisite for this class: ch.22-24 (“Model”) from R for Data Science - http://r4ds.had.co.nz/model-intro.html Let us explore how we can apply linear models with the Understanding Society data for your reports. First we need to read in the data. This is the same data frame that I used for Data visualisation 2. I saved it then so now I can simply open the file. library(tidyverse) UndSoc &lt;- readRDS(&quot;myData/all7clean.rds&quot;) We have a variable for interest in politics (vote6) and we will take it as the outcome variable we want to study. It is a discrete variable measured on a four-point scale (from “not at all interested” to “very interested”). It is an ordinal rather than continuous variable so strictly speaking it is not statisticaly appropriate to calculate the mean of this variable and to use simple linear regression. You will see though that we can still do this and learn something interesting from this exercise. First let us look at the distribution of the variable. table(UndSoc$vote6) ## ## fairly not al all not very very ## 102212 84351 86790 30981 To do the modelling we want to recode it to numeric. I will do this in such a way that larger values indicate stronger interest in politics. UndSoc &lt;- UndSoc %&gt;% mutate(polinterest = recode(vote6, &quot;very&quot; = &quot;4&quot;, &quot;fairly&quot; = &quot;3&quot;, &quot;not very&quot; = &quot;2&quot;, &quot;not al all&quot; = &quot;1&quot;)) %&gt;% mutate(polinterest = as.numeric(polinterest)) table(UndSoc$polinterest) ## ## 1 2 3 4 ## 84351 86790 102212 30981 12.1 Cross-sectional analysis Let us start from cross-sectional analysis, i.e. the analysis of the data at one point in time. You can choose any wave to do this; I will go with wave 1. First I create a separate data frame for wave 1 only. wave1 &lt;- UndSoc %&gt;% filter(wave == &quot;a&quot;) %&gt;% filter(!is.na(dvage)) 12.1.1 Age and political interest We will start with the association between age and political interest. It is always a good idea to start with visualisations. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest)) + geom_smooth() I fit a non-parametric smooth here with geom_smooth, and the association between age and political interest seems to be non-linear. We can also fit a regression line and see how well it describes the data. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest)) + geom_smooth() + geom_smooth(method = &quot;lm&quot;, colour = &quot;red&quot;) Up to the age of about 70 years two lines are pretty close and I’d say that the linear function adequately describes the data. However, for people older than 75 the linear assocition is inadequate and provides a really poor fit. 12.1.2 Sex and political interest Let us look at a bar chart showing the association between sex and political interest. wave1 %&gt;% ggplot(aes(x = sex, y = polinterest)) + geom_bar(stat = &quot;summary&quot;, fun.y = &quot;mean&quot;) We see that mean political interest is somewhat higher for men compared to women. 12.1.3 Linear model As I said above, the outcome variable is ordinal so fitting a linear model will have some limitations. For our purposes this is fine though. For your reports you should fit a linear model for ordered and binary outcomes. The linear model for binary outcomes is called the linear probability model. Please do not estimate logit or probit models for the purpose of this assignment. Of course, you cannot fit a linear model for nominal outcomes. If you outcome is nominal (this is unlikely), you should either stay with descriptive statistics and graphs or use a multinomial logit model. You should only do this if you are confident that you know what you are doing. Now we can fit a simple linear regression model with two predictors: age and sex. m1 &lt;- lm(polinterest ~ sex + dvage, wave1) summary(m1) ## ## Call: ## lm(formula = polinterest ~ sex + dvage, data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.8578 -0.9275 -0.0703 0.7293 2.1042 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.7688374 0.0123862 142.81 &lt;2e-16 *** ## sexmale 0.3115085 0.0087412 35.64 &lt;2e-16 *** ## dvage 0.0079332 0.0002393 33.16 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.946 on 47527 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.04805, Adjusted R-squared: 0.04801 ## F-statistic: 1199 on 2 and 47527 DF, p-value: &lt; 2.2e-16 Both age and sex are highly statistically significant predictors of political interest. Men on average are 0.3 points higher on the political interest scale. For age, a one-year difference is associated with about 0.01 change in political interest (older people are more interested). For two people with the age difference of about 30 years this corresponds to the difference in political interest of about 0.3. We have seen that the association between age and political interest is non-linear. To model this, we may want to include the quadratic term for age. m2 &lt;- lm(polinterest ~ sex + dvage + I(dvage^2), wave1) summary(m2) ## ## Call: ## lm(formula = polinterest ~ sex + dvage + I(dvage^2), data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.61209 -0.83774 -0.09245 0.72122 2.23983 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.390e+00 2.781e-02 49.97 &lt;2e-16 *** ## sexmale 3.123e-01 8.720e-03 35.82 &lt;2e-16 *** ## dvage 2.616e-02 1.221e-03 21.42 &lt;2e-16 *** ## I(dvage^2) -1.880e-04 1.236e-05 -15.22 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9437 on 47526 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.05266, Adjusted R-squared: 0.0526 ## F-statistic: 880.7 on 3 and 47526 DF, p-value: &lt; 2.2e-16 The quadratic term is statistically significanty indicating a non-linear fit. Note, however, that the coefficients are now more difficult to interpret. We can visualise the association between age and political interest to get some idea of the effect size. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2)) Note that this visualisation does not control for sex. 12.1.4 Interaction effect between sex and age Another question we can ask is whether the association between age and political interest is the same or different for men and women. Note that in the previous model we control for sex, and the coefficient for age represents an averaged association between age and political interest for men and women. It is possible to have a situation where the association is very different for two sexes (for example, for men political interest increases with age and for women it decreases). To check this formally, we can fit a model with an interaction effect. m3 &lt;- lm(polinterest ~ sex * dvage, wave1) summary(m3) ## ## Call: ## lm(formula = polinterest ~ sex * dvage, data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.82832 -0.91573 -0.06676 0.71663 2.11783 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.7479264 0.0157990 110.636 &lt;2e-16 *** ## sexmale 0.3587056 0.0238008 15.071 &lt;2e-16 *** ## dvage 0.0083904 0.0003213 26.115 &lt;2e-16 *** ## sexmale:dvage -0.0010263 0.0004814 -2.132 0.033 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.946 on 47526 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.04814, Adjusted R-squared: 0.04808 ## F-statistic: 801.2 on 3 and 47526 DF, p-value: &lt; 2.2e-16 We see that the interaction effect is indeed statistically significant and negative suggesting that for men the association between age and political interest is weaker. We can also fit a quadratic model. m4 &lt;- lm(polinterest ~ sex * dvage + sex * I(dvage^2), wave1) summary(m4) ## ## Call: ## lm(formula = polinterest ~ sex * dvage + sex * I(dvage^2), data = wave1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.60079 -0.84767 -0.07443 0.71480 2.22023 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.463e+00 3.689e-02 39.674 &lt; 2e-16 *** ## sexmale 1.409e-01 5.545e-02 2.541 0.0111 * ## dvage 2.201e-02 1.629e-03 13.517 &lt; 2e-16 *** ## I(dvage^2) -1.400e-04 1.641e-05 -8.532 &lt; 2e-16 *** ## sexmale:dvage 9.684e-03 2.462e-03 3.933 8.41e-05 *** ## sexmale:I(dvage^2) -1.120e-04 2.493e-05 -4.494 7.02e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9435 on 47524 degrees of freedom ## (3464 observations deleted due to missingness) ## Multiple R-squared: 0.05318, Adjusted R-squared: 0.05308 ## F-statistic: 533.9 on 5 and 47524 DF, p-value: &lt; 2.2e-16 The interaction effect is highly statistically significant. To make sense of the association between age and political interest for men and women it is best to visualise this model. wave1 %&gt;% ggplot(aes(x = dvage, y = polinterest, colour = sex)) + geom_smooth(method = &quot;lm&quot;, formula = y ~ x + I(x^2)) We can see that the lines for men and women are indeed different, although the non-linear pattern of the association is similar for both sexes. 12.1.5 Checking the assumptions In Data Analysis 2 your task was to check the assumptions underlying linear regression models. This is an important step, but it is less relevant for our work in this module. Many of these assumptions are about the distribution of residuals and affect standard errors of regression coefficients. This is very important for small samples, but less important for large samples like the one we have in the Understanding Society where standard errors are usually small compared to regression coefficients and moderate violation of the regression assumpions (such as not normal distribution of the residuals and heteroskedasticity) will not affect the results much. You do not have to show how you have checked the assumptions in your reports (although if you want to do it for yourself this would not hurt). Another common question is the interpretation of the R-squared coefficient. In Model 4 the R-squared coefficients was about 0.05 suggesting that age and sex can jointly account for about 5% of the variance of political interest. Is this an indication that the model is really poor? Yes, if your task is to build a model that predicts political interest well. This shows that just knowning a person’s age and sex you can only make a wild guess about their level of political interest (this isn’t really surprising). However, if our task is simply to explore the association between age, sex and political interest rather than to build a model that predicts political interest well, then we should not pay too much attention to R-squared. 12.1.6 Presenting the output for multiple regression models How to present the regression output in your reports? You can of course simply fo summary(m1) as we did above, but this does not look really nice. Another way is to use the package stargazer. Note that stargazer will only work if you knit your reports as pdf rather than Word. To knit as pdf you will need to install LaTeX on your computers (see https://www.latex-project.org). This is how the table produced by stargazer will look like. library(stargazer) stargazer(m1, m2, m3, m4, type = &quot;html&quot;) Dependent variable: polinterest (1) (2) (3) (4) sexmale 0.312*** 0.312*** 0.359*** 0.141** (0.009) (0.009) (0.024) (0.055) dvage 0.008*** 0.026*** 0.008*** 0.022*** (0.0002) (0.001) (0.0003) (0.002) I(dvage2) -0.0002*** -0.0001*** (0.00001) (0.00002) sexmale:dvage -0.001** 0.010*** (0.0005) (0.002) sexmale:I(dvage2) -0.0001*** (0.00002) Constant 1.769*** 1.390*** 1.748*** 1.463*** (0.012) (0.028) (0.016) (0.037) Observations 47,530 47,530 47,530 47,530 R2 0.048 0.053 0.048 0.053 Adjusted R2 0.048 0.053 0.048 0.053 Residual Std. Error 0.946 (df = 47527) 0.944 (df = 47526) 0.946 (df = 47526) 0.943 (df = 47524) F Statistic 1,199.426*** (df = 2; 47527) 880.675*** (df = 3; 47526) 801.192*** (df = 3; 47526) 533.896*** (df = 5; 47524) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 In your reports you will knit as LaTeX rather than html so you should do something like: ```{r results = 'asis'} stargazer(m1, m2, m3, m4, type = \"latex\") ``` The results argument shoud be set to asis so that the results are displayed correctly. Note that type is latex. stargazer has many options to customise the tables. Please do experiment with them. 12.2 Longitudinal analysis Now we may want to model how things change over time (i.e. do longitudinal modelling). 12.2.1 Simple model We will start from simply plotting mean political interest over time. # First let us code the variable for year. UndSoc &lt;- UndSoc %&gt;% mutate(year = dplyr::recode(wave, &quot;a&quot; = &quot;2009&quot;, &quot;b&quot; = &quot;2010&quot;, &quot;c&quot; = &quot;2011&quot;, &quot;d&quot; = &quot;2012&quot;, &quot;e&quot; = &quot;2013&quot;, &quot;f&quot; = &quot;2014&quot;, &quot;g&quot; = &quot;2015&quot;)) %&gt;% mutate(year = as.numeric(year)) UndSoc %&gt;% group_by(year) %&gt;% summarise( meanPI = mean(polinterest, na.rm = TRUE) ) %&gt;% ggplot(aes(x = year, y = meanPI)) + geom_point() + geom_line() The model that describes this chart will be the following. m5 &lt;- lm(polinterest ~ as.factor(year), UndSoc) summary(m5) ## ## Call: ## lm(formula = polinterest ~ as.factor(year), data = UndSoc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.3387 -1.2137 -0.2253 0.7295 1.7863 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.2705028 0.0044708 507.848 &lt; 2e-16 *** ## as.factor(year)2010 0.0009813 0.0062259 0.158 0.875 ## as.factor(year)2011 -0.0451822 0.0063862 -7.075 1.50e-12 *** ## as.factor(year)2012 -0.0567904 0.0064826 -8.760 &lt; 2e-16 *** ## as.factor(year)2013 -0.0262915 0.0065703 -4.002 6.29e-05 *** ## as.factor(year)2014 0.0099673 0.0067440 1.478 0.139 ## as.factor(year)2015 0.0681780 0.0066526 10.248 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9747 on 304327 degrees of freedom ## (280369 observations deleted due to missingness) ## Multiple R-squared: 0.001471, Adjusted R-squared: 0.001451 ## F-statistic: 74.7 on 6 and 304327 DF, p-value: &lt; 2.2e-16 We can see from this model that in 2011 to 2013 political interest was statistically significantly lower than in 2009, and in 2015 it was statistically significantly higher. 12.2.2 Adding a time-constant variable We may want to check if the change in political interest depends on a time-constant variable such as sex. Was the change in mean political interest similar for men and women? UndSoc %&gt;% filter(!is.na(sex)) %&gt;% group_by(year, sex) %&gt;% summarise( meanPI = mean(polinterest, na.rm = TRUE) ) %&gt;% ggplot(aes(x = year, y = meanPI, colour = sex)) + geom_point() + geom_line() It does not look like there was an interaction between sex and year, but we can check it formally. m6 &lt;- lm(polinterest ~ as.factor(year)*sex, UndSoc) summary(m6) ## ## Call: ## lm(formula = polinterest ~ as.factor(year) * sex, data = UndSoc) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.51330 -1.06358 -0.08411 0.80109 1.93642 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.1316987 0.0058923 361.777 &lt; 2e-16 *** ## as.factor(year)2010 0.0034852 0.0082076 0.425 0.671108 ## as.factor(year)2011 -0.0542942 0.0084160 -6.451 1.11e-10 *** ## as.factor(year)2012 -0.0681161 0.0085534 -7.964 1.68e-15 *** ## as.factor(year)2013 -0.0475894 0.0086757 -5.485 4.13e-08 *** ## as.factor(year)2014 -0.0020655 0.0089103 -0.232 0.816686 ## as.factor(year)2015 0.0672156 0.0087858 7.651 2.01e-14 *** ## sexmale 0.3150753 0.0088775 35.491 &lt; 2e-16 *** ## as.factor(year)2010:sexmale -0.0061332 0.0123615 -0.496 0.619786 ## as.factor(year)2011:sexmale 0.0208112 0.0126810 1.641 0.100772 ## as.factor(year)2012:sexmale 0.0238450 0.0128683 1.853 0.063883 . ## as.factor(year)2013:sexmale 0.0451257 0.0130399 3.461 0.000539 *** ## as.factor(year)2014:sexmale 0.0235125 0.0133829 1.757 0.078935 . ## as.factor(year)2015:sexmale -0.0006904 0.0132029 -0.052 0.958299 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9608 on 304318 degrees of freedom ## (280371 observations deleted due to missingness) ## Multiple R-squared: 0.02969, Adjusted R-squared: 0.02965 ## F-statistic: 716.2 on 13 and 304318 DF, p-value: &lt; 2.2e-16 This suggest that the gap in political interest between men and women was slighty hgher in 2013, but the effect size is really small. 12.2.3 Adding a time-varying variable Things get more tricky (and more interesting) if we want to add a time-varying variable such as age to the analysis. We have already modelled the association between age and political interest cross-sectionally. This answers the question of whether there is any difference in political interest between people of different age. Another question that we may want to ask is whether political interest changes when people get older. Note that this is a different question, and answering it requires the use of longitudinal data. To answer this question we need to apply regression models with fixed effects. You have not covered these models in Data Analysis 2. The main idea is to look at the changes for the same individuals. We want to see if for each person in the data getting older is associated with the changes in political interest, and then we can average the effects across different people. In other words, instead of fitting the model that compares between individuals we want to compare within individuals. Technically, we can achieve this by simply controlling for individual id. With the data of our size the model will be very difficult to estimate, so for the demonstration purposes I will select 500 random individuals from the data and run the model for them. # creating a data frame with data for 500 random people set.seed(1) random500 &lt;- sample(unique(UndSoc$pidp), 500) UndSoc500 &lt;- UndSoc %&gt;% filter(pidp %in% random500) m7 &lt;- lm(polinterest ~ as.factor(year) + as.factor(pidp) + dvage, UndSoc500) If we run summary(m7) now we will get a really long output with 499 coefficients for pidp. I will use stargazer to present the results and will omit these coefficients (called individual fixed effects) and the coefficients for year. stargazer(m7, omit = c(&quot;pidp&quot;, &quot;year&quot;), type = &quot;html&quot;) Dependent variable: polinterest dvage 0.019 (0.071) Constant 2.605 (4.254) Observations 1,800 R2 0.760 Adjusted R2 0.677 Residual Std. Error 0.551 (df = 1333) F Statistic 9.079*** (df = 466; 1333) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Note that the coefficient for age is not statisticaly significant. This indicates that as people get older their interest in politics does not change much, at least in our sub-sample of 500 people. A more efficient way to estimate fixed effects model is to use the package plm. library(plm) m8 &lt;- plm(polinterest ~ dvage, data = UndSoc500, model = &quot;within&quot;, index = c(&quot;pidp&quot;, &quot;year&quot;), effect = &quot;twoways&quot;) summary(m8) ## Twoways effects Within Model ## ## Call: ## plm(formula = polinterest ~ dvage, data = UndSoc500, effect = &quot;twoways&quot;, ## model = &quot;within&quot;, index = c(&quot;pidp&quot;, &quot;year&quot;)) ## ## Unbalanced Panel: n = 460, T = 1-7, N = 1800 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -1.72200 -0.26171 0.00000 0.20677 2.19176 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## dvage 0.019376 0.070879 0.2734 0.7846 ## ## Total Sum of Squares: 404.82 ## Residual Sum of Squares: 404.79 ## R-Squared: 5.606e-05 ## Adj. R-Squared: -0.34951 ## F-statistic: 0.0747324 on 1 and 1333 DF, p-value: 0.78461 Asking for the twoways effect means that we fit the model with individual and year fixed effects. Note that the effect size is exactly the same in models 7 and 8 (becuase this is essentially the same model), but plm will work faster. With plm you may be able to estimate the fixed effects model with the full data for your reports, although the estimation will take you some time. I will not do this here. 12.3 Further reading If you want to use linear models in your assignment I strongly recommend you consult the following book (available as an e-book in the library): J.Fox, S.Weisberg. (2011). An R Companion to Applied Regression. 2nd ed. Sage. The chapter on factors and interactions will be particularly useful. If you want to know more about fixed effects models see P.D.Allison. (2008). Fixed Effect Regression Models. Sage. To learn how to use the package plm read Y.Croissant, G.Millo. Panel Data Econometrics in R: The plm Package. https://cran.r-project.org/web/packages/plm/vignettes/plm.pdf "]
]
